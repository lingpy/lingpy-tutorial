{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Comparison with LingPy\n",
    "\n",
    "## 0.0 Notes on how to modify content for all contributors\n",
    "A general note on all contributors modifying this notebook. If you use references, please follow the following style (we'll add them with a script later when exporting to markdown):\n",
    "```markdown\n",
    "This text was written with help of the manual by [Author (Year)](:bib:AuthorYear)\n",
    "```\n",
    "\n",
    "## Normal introduction\n",
    "\n",
    "\n",
    "This tutorial will run you through the major steps needed in order to infer cognates automatically with [LingPy](http://lingpy.org) ([List and Forkel 2017](:bib:List2017i)) from linguistic word list data and to export the data into various formats so that you can either inspect them using tools like the [EDICTOR](http://edictor.digling.org) ([List 2017](:bib:List2017d)), or further analyse them, using software like [SplitsTree](http://splitstree.org) ([Huson 1998](:bib:Huson1998)) or [BEAST](http://www.beast2.org) ([Bouckaert et al. 2014](:bib:Bouckaert2014)).\n",
    "\n",
    "Basically, this tutorial assumes that you have at least an undergraduate level understanding of historical linguistics (particularly the basic methods used in historical language comparison, often summarized under the label \"comparative method\"), requiring only working knowledge of Python and command line operation. +++@tiago, please add additional info on required knowledge for running this tutorial+++\n",
    "\n",
    "It is required that you have installed both LingPy in the version [2.6](https://github.com/lingpy/lingpy/releases/tag/v2.6) for Python3 (as this tutorial will assume that you use Python3) available on [GitHub](https://github.com/lingpy/lingpy), and (as a plus) the [python-igraph](http://igraph.org) package ([Cs√°rdi and Nepusz 2006](:bib:Csardi2006)). Furthermore, in order to follow all examples given in this tutorial, it is useful to work with the [ipython](http://ipython.org) suite, which is very convenient for testing code pieces directly against the Python interpreter.\n",
    "\n",
    "The tutorial is divided into different blocks, during which different aspects of sequence comparison will be illustrated from the concrete perspective of LingPy. In order to understand fully all that is going on, however, this tutorial won't be sufficient, and it is recommended that those who are interested in the algorithmic and conceptual details of LingPy's major algorithms for sequence comparison have a closer look at the book [Sequence Comparison in Historical Linguistics](https://sequencecomparison.github.io) ([List 2014](:ref:List2014d) in which the most comprehensive state of the art is reflected. More recent papers might occasionally be mentioned in order to account for those aspects of sequence comparison which have been changed since then, but the book on sequence comparison (which is also freely available for download) is still the best starting point.\n",
    "\n",
    "The tutorial is divided into the following parts:\n",
    "\n",
    "1. Inttroduction (this part)\n",
    "2. Hands on the Data: Preparing, Loading, and Testing Word List Data\n",
    "3. Phonetic Alignment\n",
    "4. Automatic Cognate Detection\n",
    "5. Evaluation\n",
    "6. Exporting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Installation Instructions\n",
    "\n",
    "This tutorial assumes you are using a Linux system and that you have a standard Python interpreter installed (supporting either Python version 2 or Python version 3). If you are using a different operating system, you can find instructions on installing Python at [this link](http://docs.python-guide.org/en/latest/starting/installation/).\n",
    "\n",
    "To check if you have Python installed, and to find out which version in case you are not sure, open a command prompt and run the command below, which, if Python is installed, should return something similar to `Python 2.7.12`.\n",
    "\n",
    "```shell\n",
    "$ python --version\n",
    "```\n",
    "\n",
    "In case you are using or planning to use Python 3, the command below should return somethin like `Python 3.5.2`.\n",
    "\n",
    "```shell\n",
    "$ python3 --version\n",
    "```\n",
    "\n",
    "Before proceeding with LingPy installation, make sure your system is updated. Debian systems (including all Ubuntu flavors) are updated with the `sudo apt update && sudo apt upgrade` command, RedHat systems (such as Fedora) with the `yum update` command, and Arch systems with the `pacman -Syu` command. Most distributions have similar and equivalent commands.\n",
    "\n",
    "Following the best practices of Python development, we recommend you install LingPy and all its dependencies with the `pip` package manager. `pip` is included in all recent version of Python, but your distribution might not include it; in this case, it is recommended that you [properly install `pip` according to its instructions](https://pip.pypa.io/en/stable/installing/) instead of relying on your distribution repositories (which might be outdated and can lead to errors). You can check if `pip` is installed by running the command below, which should return something like `pip 9.0.1 from /usr/local/lib/python3.5/dist-packages (python 3.5)` (depending on your setup, the command might be `pip3` for Python 3).\n",
    "\n",
    "```shell\n",
    "$ pip --version\n",
    "```\n",
    "\n",
    "If `pip` is available, you can proceed to installing the LingPy library. It can be installed either by using the packaged version in the `pip` repositories or by making a full local copy of the development file on GitHub. The first alternative is recommended if you are new to Python and to LingPy, while the second is the best choice if you plan to contribute to LingPy development or alter it (in which case, however, you should be proficient enough with `git` to fork the repository and should probably use a virtual environment). In any case, both alternatives work in the same way for the purposes of this tutorial.\n",
    "\n",
    "### 1.1 Installing from pip\n",
    "\n",
    "### 1.2 Installing from git\n",
    "\n",
    "When installing the development version you will locally clone the `git` repositories and instruct `pip` to use the local copy as source, so that any changes to the code can immediately be used (without having to package lingpy or submit a pull request to the authors). You must make sure you have `git` properly installed by running the `git --version` command and installing `git` if needed (on Debian systems, with `sudo apt install git`).\n",
    "\n",
    "Remember that for a full installation you must be able to compile some C modules (with `gcc` as the standard compiler) and must have the the Python development libraries installed.\n",
    "\n",
    "Will install dependencies such as numpy, appdirs, etc. (those are listed in the `requirements.txt` file).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "+++ @tresoldi will give a first run on this, please make sure to cover:\n",
    "\n",
    "* pip install (via pypi), but also:\n",
    "* setup.py develop\n",
    "\n",
    "also make sure to tell users to install:\n",
    "\n",
    "* https://bambooforest/segments/ (will be published on Pypi as segments)\n",
    "* python-igraph\n",
    "* ipython-notebook\n",
    "* python-newick \n",
    "* cldf\n",
    "+++\n",
    "\n",
    "ON A FRESH DEBIAN SYSTEM\n",
    "\n",
    "```shell\n",
    "sudo apt update\n",
    "sudo apt upgrade\n",
    "sudo apt install build-essential git curl\n",
    "curl -O https://bootstrap.pypa.io/get-pip.py\n",
    "sudo python3 get-pip.py\n",
    "git clone https://github.com/lingpy/lingpy.git\n",
    "pip3 install --user python-igraph\n",
    "pip3 install --user -e lingpy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hands on the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Testset\n",
    "\n",
    "Linguists are often skeptical when they hear that LingPy requires explicit phonetic transcriptions, and often, they are even reluctant to interpret their data along the lines of the International Phonetic Alphabet. But in order to give the algorithms a fair chance to interpret the data in the same way in which they would be interpreted by linguists, a general practice for phonetic transcriptions is indispensable. \n",
    "\n",
    "For our test, we will use a dataset consisting of 31 Polynesian languages taken from the [ABVD](http://language.psy.auckland.ac.nz/austronesian/) ([Greenhill et al. 2008](:bib:Greenhill2008)). This dataset was intensively revised and cleaned by converting the original transcriptions into a valid version of IPA accepted by LingPy (for details, see 2.4 below). The testset is located in the same folder in which you also find this interactive tutorial, which we provide in various formats. In the following, we will assume that you opened the terminal in this folder (or ``cd``ed into this folder after opening your terminal) so that in case you type the following command, you will see similar output as given \n",
    "\n",
    "```shell\n",
    "$ ls\n",
    "```\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The Input Format\n",
    "\n",
    "Let us start by quickly examining the file `polynesian.tsv` which we prepared for this occasion. This file is a tab-separated text file with the first row indicating the header, and the very first column is reserved for numeric identifiers. If you open this file in a spreadsheet editor (and make sure to select \"tab\" as a delimiter, and NO characters to delimit a cell), will see that it is a very straightforward spreadsheet, in which the first row is a header indicating the names of the columns, and the first cell is reserved for an identifier, which should be numeric (but order does not matter).\n",
    "\n",
    "ID | DOCULECT | CONCEPT | GLOTTOCODE | CONCEPTICON_ID | VALUE | FORM | TOKENS | VARIANTS | SOURCE | COGID | LOAN\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "188 | Emae_1030 | Eight | emae1237 | 1705 | Œ≤aru | Œ≤aru | Œ≤ a r u |  | 52375 | 750 | False\n",
    "447 | RennellBellona_206 | Eight | renn1242 | 1705 | ba≈ãgu | ba≈ãgu | b a ‚Åøg u |  | POLLEX | 750 | False\n",
    "703 | Tuvalu_753 | Eight | tuva1244 | 1705 | valu | valu | v a l u |  | 29903 | 750 | False\n",
    "927 | Sikaiana_243 | Eight | sika1261 | 1705 | valu | valu | v a l u |  | POLLEX | 750 | False\n",
    "1135 | Penrhyn_235 | Eight | penr1237 | 1705 | varu | varu | v a r u |  | POLLEX | 750 | False\n",
    "6114 | Kapingamarangi_217 | Eight | kapi1249 | 1705 | waru | waru | w a r u | walu | POLLEX | 750 | False\n",
    "\n",
    "You may even prepare your data in a spreadsheet to then analyze it in LingPy. You just need to make sure to export it properly to the TSV format (which you can easily do by just copy-pasting it into an empty text-file). What you need to know about the format, however, is the following:\n",
    "\n",
    "1. contrary to most linguists' intuition, the columns do **not** indicate languages: each row indicates one word and, as a result, language names need to be redundantly repeated\n",
    "2. certain columns are **required** by LingPy, and their number can vary, depending on the task you want to carry out: for the purpose of cognate detection, you need at least the columns `doculect`, `concept`, and either a plain transcription (the default column name is `ipa`) or a more advanced and less ambiguous transcription in segmented form (the default column name is `tokens`).\n",
    "3. in order to increase readability, column headers are upper-case when LingPy writes them to file, but this is not required (internally all columns are represented as lowercase when loaded into LingPy's objects)\n",
    "4. depending on the names of the columns, values will be interpreted by default: if you have a column called `cogid`, this will be converted to an integer, and `tokens` usually assumes that you have a string separated by spaces. As a result, LingPy may throw an error if your columns do not follow these required formats. To check how columns are interpreted, you can check the file [wordlist.rc](https://github.com/lingpy/lingpy/blob/master/lingpy/data/conf/wordlist.rc) where you will find a full account of currently supported values.\n",
    "\n",
    "Not all of the columns in the table above are fully \"standardized\". The `DOCULECT` one, for example, so far only requires that distinct languages are given distinct names, no matter what those names contain (as long it has no tabulation stops). But for the purpose of exporting the data to other formats afterward, it is useful to restrict to alphanumeric names here, and to exclude all brackets or spaces from the language names, as we have been doing in this test set. This becomes especially important when inferring trees or using trees in further LingPy analyses: as trees are represented in the [Newick](https://en.wikipedia.org/wiki/Newick_format) format, where brackets play an important role, brackets in the names for the doculects will confuse the algorithm and raise an error.\n",
    "\n",
    "+++*Tiago - Considering that the paragraph below explains where the GLOTTOCODE and CONCEPTICON_ID come from, it might be worth explaining where the DOCULECT ids for this example come from, too.*\n",
    "+++\n",
    "+++*mattis - yes, should be done, they come from ABVD*+++\n",
    "\n",
    "As the last point, note that we list `GLOTTOCODE` and `CONCEPTICON_ID`, which follows two major requirements for word list data we try to establish for the [Cross-Linguistic Data Formats (CLDF)](http://cldf.clld.org) initiative. As the linguistic sign has three major dimensions, the *language*, the *meaning*, and the *word form*, `GLOTTOCODE`, the language identifier provided by the [Glottolog project](http://glottolog.org) ([Hammarstr√∂m, Forkel and Haspelmath 2017](:ref:Hammarstroem2017)) and `CONCEPTICON_ID`, the meaning identifier provided by the [Concepticon project](http://concepticon.clld.org) ([List, Cysouw, and Forkel 2016](:ref:List2016a) cover two of these aspects, while the third aspect, the consistency of the form, is currently covered by LingPy (more on this below).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Loading the Data into a `Wordlist` Object\n",
    "\n",
    "Loading the data into LingPy is straightforward. LingPy has a couple of classes which are specifically designed to handle word list data, and these classes provide all similar basic functions, plus additional ones for specific purposes:\n",
    "\n",
    "* `Wordlist`: Basic class with core functionality, allows to read, modify, and write word list data, also allows  calculating distance matrices from cognate sets as well as rudimentary tree reconstruction functions (UPGMA, [Sokal and Michener 1958](:ref:Sokal1958), Neighbor-joining, [Saitou and Nei 1987](:ref:Saitou1987)).\n",
    "* `Alignments`: Class allows to align all cognate sets in a word list. Requires one column which stores the cognate sets as well as a column for `doculect`, `concept`, and transcription (default: `ipa`) or user-defined *segmented transcription* (default: `tokens`). Alignments can be carried out in different ways, the algorithms follow the ones first described in [List (2012a)](:ref:List2012b).\n",
    "* `LexStat`: Core class for automatic cognate detection, following the algorithm first described in [List (2012b)](:ref:List2012a) and later expanded in [List (2014)](:ref:List2014d), and [List, Greenhill, and Gray (2017)](List2017c). \n",
    "* `Partial`: Recent algorithm proposed in [List, Lopez, and Bapteste (2016)](:ref:List2016g), allows -- provided data is morpheme-segmented -- to search for partial cognates in the data.\n",
    "\n",
    "We will start with the basic `Wordlist` object to illustrate some core facilities below (command line: ```$ python3 autocogs.py wordlist1```)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Segmentation of Phonetic Entries\n",
    "\n",
    "+++ todo: add statement on vanilla segmentation, plus EDICTOR checking, plus creating orthography profile +++\n",
    "\n",
    "In addition to the \"normal\" requirement of the data to be written in IPA, LingPy offers to provide the explicit segmentation of the data into sound segments. Segmentation is represented as a space-separated string in the input data, as you can see when looking at the table above, right in the cells of the `TOKENS` column. While segmentation looks unspectacular in these cases where each sound is represented by only one symbol, it may become problematic when dealing with affricates, pre-aspirated sounds, and complex vowels. The problem is usually that IPA transcriptions are inherently ambiguous, and this ambiguity is then passed on to the algorithms which cannot handle it. For example, a word like German `[`apf…ôl`]` \"apple\" could be either segmented as `[` a p f …ô l `]`, or, and historically more consistently, as `[` a pf …ô l `]`. But if the latter reading is intended (and this is usually language-family-specific), the only way to handle this consistently in IPA would be to put the bar over it: `[`apÕ°f…ôl`]`. This practice, however, would still render the detection of pre-aspiration and other cases impossible. Although LingPy deals rather well with explicit IPA, we recommend all users to segment the data themselves and indicate this by placing one column in their input word list, in which the phonetic entries are explicitly segmented by a space (with the underscore being used to mark original spaces, i.e., word breaks).\n",
    "\n",
    "LingPy's `sequence`-package offers many functions to handle phonetic sequences and to segment them automatically. As an example, consider the following code-pieces and try to find out what they are actually doing (or trigger ```$ python3 autocog.py segments``` in the command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th o x t a \t->\t th\to\tx\tt\ta\n",
      "thoxta   \t->\t t\th\to\tx\tt\ta\n",
      "thoxta   \t->\t th\to\tx\tt\ta\n",
      "apf…ôl   \t->\t a\tp\tf\t…ô\tl\n",
      "apf…ôl   \t->\t a\tpf\t…ô\tl\n",
      "t ∞oxt…ê   \t->\t t ∞\to\tx\tt\t…ê\n",
      "d…îÀêt…ôr   \t->\t d\t…îÀê\tt\t…ô\tr\n"
     ]
    }
   ],
   "source": [
    "# +++ modify example +++\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from lingpy import *\n",
    "\n",
    "seq1, seq2, seq3, seq4, seq5 = \"th o x t a\", \"thoxta\", \"apf…ôl\", \"t ∞oxt…ê\", \"d…îÀêt…ôr\"\n",
    "\n",
    "print(seq1, \"\\t->\\t\", '\\t'.join(ipa2tokens(seq1)))\n",
    "print(seq2, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq2)))\n",
    "print(seq2, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq2, semi_diacritics=\"h\")))\n",
    "print(seq3, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq3)))\n",
    "print(seq3, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq3, semi_diacritics=\"f\")))\n",
    "print(seq4, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq4)))\n",
    "print(seq5, \"  \\t->\\t\", '\\t'.join(ipa2tokens(seq5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from these examples that LingPy's `ipa2tokens` function automatically identifies diacritics and the like, but that you can also tweak it to some extent. If the sequence contains white spaces, as in the first example, `ipa2tokens` will split by white space and assume that the data is *already* segmented. We won't go into the details of this and other functions here, but you should consider giving the documentation a proper read before you start spending time on segmenting your data manually. At the same time, when trusting LingPy's default algorithm for segmentation, you should always make sure after using it that the segmentations make sense. If they are largely wrong or problematic, you should refine them before running any automatic cognate detection method.\n",
    "\n",
    "An alternative is to use the `segments` package by Steven Moran, whose main idea is more comprehensively described in [Moran and Cysouw (2017)](:ref:Moran2017). We have in fact been using it for our working example in order to segment the ABVD data on Polynesian languages properly, but it would require more time to introduce you to all the details at this point. Just keep in mind that segmentation is **crucial** for automatic cognate detection and that it is your responsibility to make sure that the algorithms \"understand\" the data you give them to analyze.\n",
    "\n",
    "Above, I wrote that LingPy takes care of the *word form* as one of the units of the linguistic sign in the classical \"Saussurean\" model. But how can we know whether LingPy recognizes a symbol or not? For this, we need to understand what LingPy does internally with word forms. Here, LingPy follows [Dolgopolsky's (1964)](:ref:Dolgopolsky1964) idea of \"sound classes\", namely the idea that we can break down the complexity inherent in phonetic transcription to some major classes of sounds so that those sounds represent some kind of a coherent unit. Dolgopolsky was thinking of sounds which often occur in correspondence relation to each other, assuming that there is a certain sound-correspondence probability inherent in all sounds (see also [Brown, Holman, and Wichmann 2013](:ref:Brown2013)). In my experience so far, this is definitely one important aspect, but even more important is the role of reducing variation which is unnecessary for historical comparison while at the same time maintaining a sufficient degree of distinctiveness. For this reason, I expanded Dolgopolsky's original system of only 10 sound classes to as many as 25 sound classes, and LingPy further offers the alphabet which was used for the [ASJP project](http://asjp.org) ([Wichmann, Holman, and Brown 2014](Wichmann2014)), which consists of 40 symbols in a slightly modified version. The following image illustrates the differences between these sound class alphabets and also shows how they represent the Greek word for \"daughter\".\n",
    "\n",
    "![image](soundclasses.jpg)\n",
    "\n",
    "How can we represent sound classes in LingPy? There is one main function that converts a segmented sound sequence into sound classes. This function `tokens2class` takes as input a list or a tuple of segments, that is, the output which you would also get when calling `ipa2tokens`, and a valid sound class model. You can theoretically create models yourself, and pass them as an instance of a specific `Model` class in LingPy, but for the moment, we will only use the ones which are there and denote them with strings, i.e., `dolgo` for Dolgopolsky's model, `sca` for my expanded model of Dolgopolsky, and `asjp` for the ASJP model). Let's just take these three and another specific model, called `art` (for \"articulation\") which gives numbers to indicate the prosody of sounds, and convert the word Greek `[`Œ∏i…£at…õra`]` into the different sound class systems (you can also trigger this by typing ```$ python3 autocogs.py classes``` in the command line).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Œ∏i…£at…õra  ->  TVKVTVRV (dolgo)\n",
      "Œ∏i…£at…õra  ->  DIGATERA (sca)\n",
      "Œ∏i…£at…õra  ->  8ixatEra (asjp)\n",
      "Œ∏i…£at…õra  ->  37371757 (art)\n"
     ]
    }
   ],
   "source": [
    "# +++ move sound classes to alignment illustrations +++\n",
    "word = \"Œ∏i…£at…õra\"\n",
    "segs = ipa2tokens(word)\n",
    "\n",
    "# iterate over sound class models and write them in converted version \n",
    "for model in ['dolgo', 'sca', 'asjp', 'art']:\n",
    "    print(word, ' -> ', ''.join(tokens2class(segs, model)), '({0})'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the conversion to sound classes is the major check whether LingPy has \"understood\" your input. If LingPy does not find a class symbol corresponding to a given segment, it will use the default character \"0\" to indicate this failure of converting a given sound sequence. This zero will be treated as an uninvited guest in most comparisons. It won't be aligned with other elements and will score negatively in the automatic cognate detection routines. You should thus try to avoid this by making sure that your sequences do not contain any errors. When carrying out cognate the detection analysis, we have a specific keyword `check` which you can set to `True` to make sure that all sequences with zeros in sound classes are excluded before the analysis is carried out. But you can easily write a Python function to check yourself in only a few lines (write ```$ python3 autocogs.py errors``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The symbol <E> occurs 1 times and is not recognized.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def check_sequence(seq):\n",
    "    \"\"\"Takes a segmented string as input and returns erroneously converted segments.\"\"\"\n",
    "    cls = tokens2class(seq, 'dolgo') # doesn't matter which model to take, all cover the same character range\n",
    "    errors = defaultdict(int)\n",
    "    for t, c in zip(seq, cls):\n",
    "        if c == '0':\n",
    "            errors[t] += 1\n",
    "    return errors\n",
    "\n",
    "word = \"Œ∏i…£atEra\"\n",
    "seq = ipa2tokens(word)\n",
    "for error, count in check_sequence(seq).items():\n",
    "    print(\"The symbol <{0}> occurs {1} times and is not recognized.\".format(error, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wordlist has 31 languages and 210 concepts across 7551 rows.\n"
     ]
    }
   ],
   "source": [
    "# load the wordlist\n",
    "wl = Wordlist('polynesian.tsv')\n",
    "\n",
    "# count number of languages, number of rows, number of concepts\n",
    "print(\"Wordlist has {0} languages and {1} concepts across {2} rows.\".format(wl.width, wl.height, len(wl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By accessing the attributes `width` we retrieve the number of languages and with `height` we retrieve the number of concepts. This follows the logic inherent in the traditional format in which linguists prepare their spreadsheets, namely by placing concepts in the first column and languages in the rest of the columns. Traditional linguistic databases would thus represent the data from the table above as follows:\n",
    "\n",
    "CONCEPT | Emae_1030 | RennellBellona_206 | Tuvalu_753 | Sikaiana_243 | Penrhyn_235 | Kapingamarangi_217 \n",
    "--- | --- | --- | --- | --- | --- | ---\n",
    "one | tasi| tahi | tahi | tasi | tahi | dahi\n",
    "five | rima | gima | lima | lima | rima | lima\n",
    "eight | Œ≤aru | ba≈ãu | valu | valu | varu | waru\n",
    "... | ... | ... | ... | ... | ... | ...\n",
    "\n",
    "The disadvantage of this annotation is, however, that we can only store one value in each cell, and we will create inconsistencies if we try to mix information per cell. For that reason, we maintain the strict tabular representation where each word is placed in one row, but internally, LingPy represents the data in multidimensional tables in which languages are thought to be placed in the columns and concepts in the rows. \n",
    "\n",
    "There are multiple ways in LingPy to inspect and manipulate data using the `Wordlist` class, but it would go too far to mention them all here, so we will restrict it to one example, by which we retrieve the values from the six languages above for the entry \"Eight\", using the `wordlist.get_dict()` function, and refer the users to a longer tutorial which is [online](http://lingpy.org/tutorial/lingpy.basic.wordlist.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emae_1030              \t Œ≤aru\n",
      "RennellBellona_206     \t ba≈ãgu\n",
      "Tuvalu_753             \t valu\n",
      "Sikaiana_243           \t valu\n",
      "Penrhyn_235            \t varu\n",
      "Kapingamarangi_217     \t walu\n"
     ]
    }
   ],
   "source": [
    "# get all indices for concept \"eight\", `row` refers to the concepts here, while `col` refers to languages\n",
    "eight = wl.get_dict(row='Eight', entry='value')\n",
    "for taxon in ['Emae_1030', 'RennellBellona_206', 'Tuvalu_753', 'Sikaiana_243', 'Penrhyn_235',  'Kapingamarangi_217']:\n",
    "    print('{0:20}'.format(taxon), '  \\t', ', '.join(eight[taxon]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking Coverage\n",
    "\n",
    "For cognate detection, it is not only important to have good phonetic transcriptions (ideally segmented in such a form that they were checked by an experienced linguist), but also to make sure that there are **enough words** in your data. If the data is too sparse, even human linguists would not be able to find any signal based on regular sound correspondences, provided they see the languages the first time and don't know their history (which is the situation for every algorithm). Following an earlier study by [List (2014b)](:ref:List2014c), we know now that at least 100 word pairs for languages as disparate as English and French are needed to provide a solid basis for automatic cognate detection. But when dealing with a large dataset of different languages, which necessarily contains a number of gaps (not all concepts can be elicited in the sources, field work has not provided enough details, etc.), it can be deleterious if the *mutual coverage* between the languages is low. \n",
    "\n",
    "By mutual coverage, I mean the number of comparable word pairs (with the same concept) for each language pair in a given dataset. We can compare different aspects of mutual coverage, such as the *average mutual coverage*, where we average the number of available word pairs, or the *minimal mutual coverage*, which provides the smallest mutual coverage of any pair of languages. In addition, one can also ask for the subset fulfilling a minimal mutual coverage for all language pairs, and this task would return the subset of languages in a `Wordlist` which all have at least the mutual coverage specified by the user. LingPy offers now (in version 2.5.1) solutions for all these problems, but since the last problem is considerably hard and computationally intensive, we won't discuss it here, but will instead simply check the minimal mutual coverage which holds for all languages in our sample. So we try to find the lower bound of concept pairs which all languages have in common (type ```$ python3 autocogs.py coverage1``` in command line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal mutual coverage is at 162 concept pairs.\n"
     ]
    }
   ],
   "source": [
    "from lingpy.compare.util import mutual_coverage_check, mutual_coverage_subset\n",
    "for i in range(210, 0, -1):\n",
    "    if mutual_coverage_check(wl, i):\n",
    "        print(\"Minimal mutual coverage is at {0} concept pairs.\".format(i))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is definitely good enough for our purpose, given the rule of thumb which says that below a minimal mutual coverage of 100 one should not do language-specific cognate detection analyses. If the coverage is lower, this does not mean you need to give up automatic cognate detection, but it means you should not use the language-specific `LexStat` method but rather a language-independent method, which does not require the information on potential sound correspondences (but will also tend to identify more false positives).\n",
    "\n",
    "Although, as I just said, the value is good enough, we should further reduce the data a bit to make sure we can inspect them better later on (otherwise, the analyses may also take a lot of time if you run them on computers with insufficient power). So what we will do right now is testing the `mutual_coverage_subset` method which returns a subset of languages for which a given minimal mutual coverage holds. We will then export our `Wordlist` object to file by specifying these languages as our subset (type ```$ python3 autocogs.py coverage2``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 languages with an average mutual coverage of 207.\n",
      "The new word list has 14 languages and 210 concepts across 3671 words.\n"
     ]
    }
   ],
   "source": [
    "count, results = mutual_coverage_subset(wl, 200)\n",
    "coverage, languages = results[0]\n",
    "print('Found {0} languages with an average mutual coverage of {1}.'.format(count, coverage))\n",
    "\n",
    "# write word list to file\n",
    "wl.output(\"tsv\", filename=\"polynesian-small\", subset=True, rows=dict(doculect = \"in \"+str(languages)))\n",
    "\n",
    "# load the smaller word list\n",
    "wl = Wordlist('polynesian-small.tsv')\n",
    "\n",
    "# print basic characteristics\n",
    "print(\"The new word list has {0} languages and {1} concepts across {2} words.\".format(\n",
    "    wl.width, wl.height, len(wl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could not further work with this selection of languages with a very high coverage, and it is always recommended to do so when working on diverse languages samples. For our further tests, however, we will restrict our selection of languages to another subset, namely the East Polynesian languages. Let us now extract those languages from the data (based on their language names) and then see how good the coverage is for this subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East Polynesian data covers 210 concepts and 10 languages.\n"
     ]
    }
   ],
   "source": [
    "eastern = ['NorthMarquesan_38', 'Austral_128', 'Austral_1213', \n",
    "            'Tahitian_173', 'Sikaiana_243', 'Maori_85', 'Hawaiian_52',\n",
    "            'Mangareva_239', 'Tuamotuan_246', 'Rapanui_264'] \n",
    "wl = Wordlist('polynesian.tsv')\n",
    "wl.output('tsv', filename='east-polynesian', subset=True,\n",
    "            rows=dict(doculect = 'in '+str(eastern)))\n",
    "\n",
    "wl = Wordlist('east-polynesian.tsv')\n",
    "print(\"East Polynesian data covers {0} concepts and {1} languages.\".format(wl.height, wl.width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now repeat the coverage experiment from above, but this time with the Eastern Polynesian language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal mutual coverage is at 179 concept pairs.\n"
     ]
    }
   ],
   "source": [
    "for i in range(210, 0, -1):\n",
    "    if mutual_coverage_check(wl, i):\n",
    "        print(\"Minimal mutual coverage is at {0} concept pairs.\".format(i))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this coverage is much less than the coverage we encountered above. Nevertheless, for our purpose it will be good enough, and the rule of thumb for closely related languages, which says, that we need more than 150 concepts mutually shared between each language pair holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Checking for Synonyms\n",
    "\n",
    "+++ add synonyms check, we have it already in a good form on the original polynesian data +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Phonetic Alignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pairwise Alignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Scoring Function\n",
    "\n",
    "+++ add info on scoring function here +++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Sound Classes \n",
    "\n",
    "+++ add info on sound classes here +++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Gap Function\n",
    "\n",
    "+++ add info on gap function here +++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Alignment mode\n",
    "\n",
    "+++ add info on alignment mode here +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multiple Alignment\n",
    "\n",
    "Phonetic alignment is *per se* independent of the existence of any word list data. Instead, it is a way to align phonetic sequences (words in phonetic transcription) in various ways. Phonetic alignment is an important pre-requisite in order to identify regular sound correspondences. Regular sound correspondences again are important to identify cognates (at least in the classical framework of the comparative method). In addition, alignment analyses are useful in presenting one's analyses in a transparent way, since, unfortunately, scholar often think that their cognate judgments are self-evident, ignoring that a linguist with another language family as their specialty will barely be able to follow the idiosyncratic discourse on language-family-specific sound change patterns and the like. \n",
    "\n",
    "In order to carry out alignment analyses in LingPy, you have a range of different possibilities, and there won't be the time to cover all of them here. Instead, I will illustrate how you can make a quick multiple alignment using the ```Multiple``` class of LingPy. This class is automatically imported when importing LingPy, and it requires a list of sequences as input. Here again, LingPy will automatically try to split your input sequences if they are not already segmentized, but we advise you to segmentize them properly before. We use four words for \"dog\" in Polynesian languages (Samoan, Hawaiian, North Marquesan, and Anuta). We do not type them in by pre-segmenting them, but rather tell LingPy to treat vowels not as dipthongs. We start with the simplest method, the *progressive alignment*, which first makes a little tree of the input sequences and then aligns them by going the tree from the leaves to the root, every time aligning two more until all are aligned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " î\tu\tl\ti\t-\n",
      " î\ti\tl\ti\to\n",
      "k\tu\t î\ti\t-\n",
      "k\to\tr\ti\t-\n"
     ]
    }
   ],
   "source": [
    "msa = Multiple([' îuli', ' îilio', 'ku îi', 'kori'], merge_vowels=False)\n",
    "print(msa.align('progressive'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more complicated algorithms available, for example, library-based alignment, following the T-Coffee algorithm ([Notredame et al. 2000](:ref:Notredame2000), based on a so-called \"library\" which is created before the tree is built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " î\tu\tl\ti\t-\n",
      " î\ti\tl\ti\to\n",
      "k\tu\t î\ti\t-\n",
      "k\to\tr\ti\t-\n"
     ]
    }
   ],
   "source": [
    "print(msa.align('library'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are still the same, which is not really surprising, given that this alignment is not very challenging, but it was shown in [List (2014)](:ref:List2014d) that this algorithm largely enhances more complex alignments.\n",
    "\n",
    "As mentioned before, the algorithms make use of a specific guide tree along with the sequences are consecutively aligned. In order to check how this guide tree looks like, you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              /-HYLI\n",
      "                    /edge.0--|\n",
      "          /edge.1--|          \\-HILIU\n",
      "         |         |\n",
      "-root----|          \\-KURI\n",
      "         |\n",
      "          \\-KYHI\n"
     ]
    }
   ],
   "source": [
    "print(msa.tree.asciiArt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the algorithm guide tree shows the sound-class reresentation of the words as the leaves of the tree. From there, it is probably also quite easy to see how the algorithm arrives at the cluster decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Cognate Detection\n",
    "\n",
    "### 4.1 Checking the Data\n",
    "\n",
    "I assume that you have thoroughly checked your data manually before running cognate detection analyses. I also assume that you do not have any of the following problems in your data:\n",
    "\n",
    "* an extensive number of synonyms in one language\n",
    "* multiple variant forms for the same word form\n",
    "* data merged from different sources without adjusting the phonetic transcription\n",
    "* mutual coverage below 100 words per language pair\n",
    "\n",
    "Before running the cognate detection analysis, you may, however, still want to check whether LingPy recognizes all your data correctly. Here, a very simple way to achieve this is to load the `LexStat` class with the specific keyword `check` set to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = LexStat('east-polynesian.tsv', check=True, segments='tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you have problems in your data encoding, you will be asked if you want to exclude the sequences automatically. As a result, a logfile, called `errors.log` will be created and point you to all erroneous sequences which contain segments which LingPy does not recognize. Let us quickly introduce some bad sequences by just converting randomly all `[`e`]` sounds to the letter A (capitals are never accepted in the normal sound class models of LingPy) and see what we get then. For this, we even do not need to re-write the data, we just add another row where we change the content, give it a random name (we call it \"tokens\", as this also signals LingPy that the input should be treated as a sequence and not as a string), and specify this for the `LexStat` instance method as the column in the file where the `segments` are. We first load the data as `Wordlist` and then pass that data directly to `LexStat` (```$ python3 autocogs.py trigger-errors``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were errors in the input data - exclude them? [y/N] y\n"
     ]
    }
   ],
   "source": [
    "wl = Wordlist('east-polynesian.tsv')\n",
    "\n",
    "# add new column \"segments\" and replace data from column \"tokens\"\n",
    "wl.add_entries('segments', 'tokens', lambda x: ['A' if y == 'e' else y for y in x])\n",
    "\n",
    "lex = LexStat(wl, segments='segments', check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now check the file `errors.log`, you will find a long file with the following first ten lines:\n",
    "\n",
    "```text\n",
    "ID\tTokens\tError-Type\n",
    "1572\t<bad character in tokens at ¬´A¬ª>\tg a t o a A l i m a\n",
    "3320\t<bad character in tokens at ¬´A¬ª>\tp a A _  î a  î u r u\n",
    "5145\t<bad character in tokens at ¬´A¬ª>\tl i m a s A f u l u\n",
    "5696\t<bad character in tokens at ¬´A¬ª>\tr i m a _ t A k a u\n",
    "12\t<bad character in tokens at ¬´A¬ª>\tp a A\n",
    "3327\t<bad character in tokens at ¬´A¬ª>\tp a A\n",
    "5153\t<bad character in tokens at ¬´A¬ª>\tA _ f aÀê\n",
    "```\n",
    "\n",
    "Each row starts with the ID of the word which is contaminated (and this links to the row-ID of your input file), it is followed by a description of the error-type, and then by a segmented form of the word form. LingPy then also creates a file called `lingpy-DATE-cleaned.tsv` (`DATE` meaning the date of the day you run LingPy), in which all contaminated words have been excluded, and this file is read in again, if you pressed \"y\", and will be the one to run the analysis. \n",
    "\n",
    "LingPy thus tries to make the enterprise of cognate detection quite convenient for you as a user, but you should be warned not to use files containing errors for publications, but only for personal test purposes, in order to improve your data. If LingPy does not recognize characters, you should not globally exclude them as a reaction, but should instead try to improve your data until it is publication-ready. Otherwise, the results will much likely be disappointing anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Overview on Algorithms\n",
    "\n",
    "LingPy comes along with four pre-defined cognate detection algorithms. These algorithms are all contained in the `LexStat` class which often confuses users, as one of the algorithms provided by `LexStat` is also called `lexstat`. Internally, however, it makes sense, as all algorithms were created at the same time, when I published the LexStat algorithm ([List 2012b](:ref:List2012a)), so I would write it into one class which I called \"LexStat\" and for the paper, I then also decided to call the algorithm \"LexStat\" since I could not think of a better name.\n",
    "\n",
    "*Tiago - I must admit that the fact the both the class and the algorithm are called `lexstat` confused me once, too. There is a lot of compatibility in place, but maybe there should be a wrapper or an alias to one of them? Your surname might not be the best alternative (`list`), but an alias as `jmlist` should be enough. You could also base the name in a description of its difference, such as in the pairwise comparisons, permutations, or in the difference between attested and expected frequencies.*\n",
    "\n",
    "Anyway, when carrying out cognate detection algorithms, it is important to keep in mind what these algorithms are based on. We can distinguish the following three major types:\n",
    "\n",
    "1. consonant-class-matching (CCM), following Dolgopolky's (1964) early idea to assume that words with two matching consonant classes would likely be cognate,\n",
    "2. phenotypic sequence similarity partitioning (PSSP), follows the general idea also applied in homology detection in biology, by which sequences are clustered into sets of homologs based on a partitioning algorithm which is applied to a distance or a similarity matrix representing the overall sequence similarity,\n",
    "3. language-specific sequence similarity partitioning (LSSP), follows the core idea of the LexStat algorithm by which sequence similarity is calculated on a language-specific basis for each language pair in the data, based on permutation statistics which give hints regarding the most likely candidates for regular sound correspondences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In LingPy, the methods which you can use to carry out these analyses have specific names, as well as the default output, a cluster decision represented as an integer identifier that assigns words to clusters. They are given in the table below:\n",
    "\n",
    "Class | Alignments? | Sound Classes? | Sound Correspondences? | Threshold?| LingPy-Name | LingPy-Output | Note\n",
    "--- | --- | --- | --- | --- | ---\n",
    "CCM | no | yes | no | no | \"turchin\" | \"turchinid\" | Consonant-class matching method close to the description in [Turchin et al. (2010)](:ref:Turchin2010))\n",
    "PSSP | yes | no | no | yes | \"edit-dist\" | \"editid\" | Vanilla edit-distance ([Levenshtein 1965](:ref:Levenshtein1965)), normalized by dividing with the longer string.\n",
    "PSSP | yes | yes | no | yes | \"sca\" | \"scaid\" | Distance score derived from SCA alignments ([List 2012a](:ref:List2012b)) by applying [Downey et al.'s (2008)](:ref:Downey2008) formula\n",
    "LSSP | yes | yes | yes | yes | \"lexstat\" | \"lexstatid\" | The core \"LexStat\" algorithm described in List ([2012b](:ref:List2012a) and [2014](:ref:List2014d))\n",
    "\n",
    "As a general rule, you should keep the following in mind (see also our experience with these methods in [List, Greenhill, and Gray (2017)](:ref:List2017c):\n",
    "\n",
    "1. if you want a fast first analysis and speed counts, take \"turchin\" (Dolgopolsky method), since it has a low amount of false positives, but it will also miss many cognates\n",
    "2. if speed does not matter and you have enough concepts (> 100) in your data, and you want to have the most reliable analysis, take \"lexstat\"\n",
    "3. if you have less than 100 concepts, and speed does not really matter, take \"sca\", as it yields consistently better results as the \"turchin\" method\n",
    "\n",
    "### 4.3 Running the Analysis\n",
    "\n",
    "Let us now, before we sink too much into the details, just start and do all four analyses on our `mikronesian.tsv` test data. Note that due to the permutation approach used by the \"lexstat\" method, we will need to write two commands here, while we need only one command for the other three methods. We start by loading the data into the `LexStat` class and will then run the \"turchin\" analyses for the start, and we then print out the results for the item \"Eight\" (```$ python3 autocogs.py cognates-turchin``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuamotuan_246        \t varu \t3\n",
      "Mangareva_239        \t varu \t3\n",
      "Austral_128          \t va îu \t2\n",
      "Rapanui_264          \t va'u \t2\n",
      "Austral_1213         \t vaGu \t1\n",
      "Hawaiian_52          \t walu \t3\n",
      "NorthMarquesan_38    \t va'u \t2\n",
      "Tahitian_173         \t va'u \t2\n",
      "Sikaiana_243         \t valu \t3\n",
      "Maori_85             \t waru \t3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lex = LexStat('east-polynesian.tsv', segments='tokens', check=True)\n",
    "\n",
    "# run the dolgopolsky (turchin) analysis, which is threshold-free\n",
    "lex.cluster(method='turchin')\n",
    "\n",
    "# show the cognate sets, stored in \"turchinid\" for the words for \"Eight\"\n",
    "eight = lex.get_dict(row='Eight') # get a dictionary with language as key for concept \"eight\"\n",
    "for k, v in eight.items():\n",
    "    idx = v[0] # index of the word, it gives us access to all data\n",
    "    print(\"{0:20} \\t {1} \\t{2}\".format(lex[idx, 'doculect'], lex[idx, 'value'], lex[idx, 'turchinid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now do the same for the \"sca\" method, but since this method is not threshold free, we will need to define a threshold. We follow the default value we know from experience, which is 0.45. We then print out the same data, but this time including the cognate judgments by all three methods (```$ python3 autocogs.py cognates-sca``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuamotuan_246        \t varu \t3 \t 1 \n",
      "Mangareva_239        \t varu \t3 \t 1 \n",
      "Austral_128          \t va îu \t2 \t 1 \n",
      "Rapanui_264          \t va'u \t2 \t 1 \n",
      "Austral_1213         \t vaGu \t1 \t 1 \n",
      "Hawaiian_52          \t walu \t3 \t 1 \n",
      "NorthMarquesan_38    \t va'u \t2 \t 1 \n",
      "Tahitian_173         \t va'u \t2 \t 1 \n",
      "Sikaiana_243         \t valu \t3 \t 1 \n",
      "Maori_85             \t waru \t3 \t 1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lex.cluster(method=\"sca\", threshold=0.45)\n",
    "\n",
    "for k, v in eight.items():\n",
    "    idx = v[0] \n",
    "    print(\"{0:20} \\t {1} \\t{2} \\t {3} \".format(\n",
    "        lex[idx, 'doculect'], \n",
    "        lex[idx, 'value'], \n",
    "        lex[idx, 'turchinid'], \n",
    "        lex[idx, 'scaid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to do the same analysis with the \"lexstat\" method. This will take some time due to the permutation test. In order to make sure we do not need to run this all the time, we will save the data immediately after running the permutation to a file which we give the extension \"bin.tsv\", and which we can load in case we want to carry out further tests, or which we can otherwise also share when publishing results, as it contains all the data needed to rerun the analyses on a different machine. LingPy creates a lot of data when analyzing wordlists, but by default, only a minimal amount of the data is written to file. In this case, if we want to store the results of the permutation test, we need to store the whole file with all the data that lingpy produces, especially the language-specific scoring function. In order to force LingPy to do so, we have to add the keyword ```ignore=[]``` to the output-function. This will prevent that any data which should be written to file is ignored (```$ python3 autocogs.py cognates-lexstat``` in commandline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-11 16:28:02,341 [WARNING] A different scoring function has already been calculated, overwriting previous settings.\n",
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuamotuan_246        \t varu \t3 \t 1 \t 1\n",
      "Mangareva_239        \t varu \t3 \t 1 \t 1\n",
      "Austral_128          \t va îu \t2 \t 1 \t 1\n",
      "Rapanui_264          \t va'u \t2 \t 1 \t 1\n",
      "Austral_1213         \t vaGu \t1 \t 1 \t 1\n",
      "Hawaiian_52          \t walu \t3 \t 1 \t 1\n",
      "NorthMarquesan_38    \t va'u \t2 \t 1 \t 1\n",
      "Tahitian_173         \t va'u \t2 \t 1 \t 1\n",
      "Sikaiana_243         \t valu \t3 \t 1 \t 1\n",
      "Maori_85             \t waru \t3 \t 1 \t 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lex.get_scorer(runs=10000)\n",
    "lex.output('tsv', filename='east-polynesian.bin', ignore=[])\n",
    "lex.cluster(method='lexstat', threshold=0.60)\n",
    "\n",
    "for k, v in eight.items():\n",
    "    idx = v[0] \n",
    "    print(\"{0:20} \\t {1} \\t{2} \\t {3} \\t {4}\".format(\n",
    "        lex[idx, 'doculect'], \n",
    "        lex[idx, 'value'], \n",
    "        lex[idx, 'turchinid'], \n",
    "        lex[idx, 'scaid'],\n",
    "        lex[idx, 'lexstatid']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there is not much difference in the results for this very item, but you should not underestimate the different power of the methods, as we will see later on when running an evaluation analysis. For now, trust me that in general the results are quite different.\n",
    "\n",
    "Let us now run (for those who managed to install the python-igraph package) an additional analysis which was shown to yield even better results. Here, we do still use the \"lexstat\" approach, but we use \"infomap\" ([Rosvall and Bergstroem 2008](:ref:Rosvall2008)) as our cluster method. This method is network-based rather than agglomerative (as is LingPy's default), and was shown to yield consistently better results in combination with \"lexstat\" ([List, Greenhill, and Gray 2017](:ref:List2017c)). In order to avoid that we override the content of the column \"lexstatid\", we now pass a specific keyword, called `ref` (the \"reference\" of the output) and set its value to \"infomap\". We also choose a different threshold, the one we empirically determined from tests on different language families (see ibd. for details, (```$ python3 autocogs.py cognates-infomap``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuamotuan_246        \t varu \t3 \t 1 \t 1 \t 1\n",
      "Mangareva_239        \t varu \t3 \t 1 \t 1 \t 1\n",
      "Austral_128          \t va îu \t2 \t 1 \t 1 \t 1\n",
      "Rapanui_264          \t va'u \t2 \t 1 \t 1 \t 1\n",
      "Austral_1213         \t vaGu \t1 \t 1 \t 1 \t 1\n",
      "Hawaiian_52          \t walu \t3 \t 1 \t 1 \t 1\n",
      "NorthMarquesan_38    \t va'u \t2 \t 1 \t 1 \t 1\n",
      "Tahitian_173         \t va'u \t2 \t 1 \t 1 \t 1\n",
      "Sikaiana_243         \t valu \t3 \t 1 \t 1 \t 1\n",
      "Maori_85             \t waru \t3 \t 1 \t 1 \t 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lex.cluster(method=\"lexstat\", threshold=0.55, ref=\"infomap\", cluster_method='infomap')\n",
    "for k, v in eight.items():\n",
    "    idx = v[0] \n",
    "    print(\"{0:20} \\t {1} \\t{2} \\t {3} \\t {4} \\t {5}\".format(\n",
    "        lex[idx, 'doculect'], \n",
    "        lex[idx, 'value'], \n",
    "        lex[idx, 'turchinid'], \n",
    "        lex[idx, 'scaid'],\n",
    "        lex[idx, 'lexstatid'],\n",
    "        lex[idx, 'infomap']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, no improvement for \"eight\", but we will see later in detail, and for now, we just write the data to file, this time in plain text, without the additional information, but with the additional columns with our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex.output('tsv', filename='east-polynesian-lexstat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Aligning the Results\n",
    "\n",
    "One great advantage of LingPy is that alignments can also be directly computed from automatically inferred cognate sets. This is useful, first also for manually annotated cognate sets, as it saves a lot of work, since alignment algorithms come very close to human judgments, and it requires only minimal post-annotation by humans to correct the errors. Second, it is useful to check the data, as it makes transparent where the algorithm found the similarity that triggered a respective cognate decision.\n",
    "\n",
    "When carrying out alignment analyses, we use the `Alignments` class in LingPy which requires a word list as input as well as the column which contains the cognate sets which shall be aligned. We will use the \"infomap\" analysis for our automatic alignments, since this usually performs better than the other methods. This is done by specifying the keyword `ref` as \"infomap\" when calling the `Alignments` class. As a further important tweak, we first load the data into the `LexStat` class so that we have the inferred sound correspondences which will then be used to compute our alignments. For this purpose, we load the file `mikronesian.bin.tsv` which stores the results of our permutation analysis and provides language-specific scores for all segments in the data (high scores indicating likely sound correspondences, low scores < 0 indicating non-corresponding sounds). We align using the normal progressive alignment, which is usually sufficient for smaller alignments and is slightly faster. When calling the alignment algorithm, we define the specific keyword `scoredict` and pass it the `lex.cscorer`, which stores the language-specific scoring functions for our data (```$ python autocogs.py alignments4``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lex = LexStat('east-polynesian.bin.tsv')\n",
    "alm = Alignments('east-polynesian-lexstat.tsv', ref='infomap', segments='tokens') # `ref` indicates the column with the cognate sets\n",
    "alm.align(method='progressive', scoredict=lex.cscorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was not very spectacular, as we have not yet seen what happened. We can visualize the alignments from the command line by picking a particular cognate set and printing the alignments on screen. The alignments are added in a specific column called `alignments` as a default (but which can be modified by specifying another value with the keyword `alignments` passed to the initialization method for the `Alignments` class). Additionally, they can be retrieved using the `Alignments.get_msa` method - since multiple different alignment analyses can be stored in the object, the reference to a particular analysis must be passed. The following code illustrates how we can print a particular aligned cognate set (```python3 autocogs.py alignments5``` in command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austral_1213         \t Eight \t v\ta\t…¢\tu\n",
      "Austral_128          \t Eight \t v\ta\t î\tu\n",
      "Hawaiian_52          \t Eight \t w\ta\tl\tu\n",
      "Mangareva_239        \t Eight \t v\ta\tr\tu\n",
      "Maori_85             \t Eight \t w\ta\tr\tu\n",
      "NorthMarquesan_38    \t Eight \t v\ta\t î\tu\n",
      "Rapanui_264          \t Eight \t v\ta\t î\tu\n",
      "Sikaiana_243         \t Eight \t v\ta\tl\tu\n",
      "Tahitian_173         \t Eight \t v\ta\t î\tu\n",
      "Tuamotuan_246        \t Eight \t v\ta\tr\tu\n"
     ]
    }
   ],
   "source": [
    "msa = alm.get_msa('infomap')['1']\n",
    "for i, idx in enumerate(msa['ID']):\n",
    "    print(\n",
    "        '{0:20}'.format(msa['taxa'][i]),  \n",
    "        '\\t',\n",
    "        alm[idx, 'concept'],\n",
    "        '\\t',\n",
    "        '\\t'.join(msa['alignment'][i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the eight, although this was not planned. But now let's quickly save the data to file, so that we can go on and inspect the findings further (command line covers this command via ```python3 autocogs.py alignments4```):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-04 15:07:52,556 [INFO] Data has been written to file <east-polynesian-aligned.tsv>.\n"
     ]
    }
   ],
   "source": [
    "alm.output('tsv', filename='east-polynesian-aligned', ignore='all', prettify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Inspecting Alignments with the EDICTOR\n",
    "\n",
    "+++ add a short notices +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Sound Correspondences\n",
    "\n",
    "+++ maybe explain simply in edictor?+++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Evaluation with LingPy\n",
    "\n",
    "#### 5.1 Manual Inspection of Differences\n",
    "\n",
    "#### 5.2 Computing B-Cubed Scores\n",
    "\n",
    "LingPy has a couple of evaluation methods implemented, and since we have original expert cognate judgments from ABVD, we can compare our findings against theirs. Comparing cognate set accuracy is not necessarily a trivial problem, as we deal with cluster comparisons, which is a topic that was debated a lot in circles outside of linguistics, and it would lead us too far away if we discussed it in detail here now. For a linguistic viewpoint with a brief working example of our preferred method, the B-Cubed scores (see [Hauer and Kondrak 2011](:ref:Hauer2011), [Bagga and Baldwin 1998](:ref:Bagga1998), and [Amigo et al. 2009](:ref:Amigo2009)), see List, Greenhill, and Gray (2017). What you need to know, however, is that evaluation in NLP circles usually comes along with the concepts of *precision*, *recall*, and *f-score*. Initially, I found them rather difficult to grasp, as historical linguists usually think in terms of false positives and false negatives. In order to understand the idea, one should think that an algorithm for cognate detection can basically do two things either right or wrong: it could cluster words which are not cognate, or it could fail to cluster words as cognate. In the first case, we would measure this in terms of precision, by counting, how often the algorithm proposes correct or incorrect answers, and in the latter case, we measure the proportion of cognate sets which are missed. In the B-Cubed measure we use, this translates roughly to a measure of false/true positives vs. false/true negatives, but it is not entirely the same. The f-score computes the harmonic mean, which summarizes both values, and we usually want to improve the f-score and we use it to compare different algorithms with each other. \n",
    "\n",
    "Let's start and do this comparison now, by loading the respective functions from the LingPy evaluation module, and computing precision, recall, and f-scores for all our different automatically inferred cognate sets with respect to the gold standard. The gold standard is located in the column `COGID` of the input file, so we need to name this when comparing with any of the other columns (like `LEXSTATID`, etc., ```$ python3 autocogs.py evaluate``` in terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turchinid \t0.95\t0.68\t0.79\n",
      "scaid     \t0.89\t0.82\t0.85\n",
      "lexstatid \t0.95\t0.89\t0.92\n",
      "infomap   \t0.94\t0.91\t0.93\n"
     ]
    }
   ],
   "source": [
    "from lingpy.evaluate.acd import bcubes, diff\n",
    "wl = Wordlist('east-polynesian-lexstat.tsv')\n",
    "\n",
    "for res in ['turchinid', 'scaid', 'lexstatid', 'infomap']:\n",
    "    print('{0:10}\\t{1[0]:.2f}\\t{1[1]:.2f}\\t{1[2]:.2f}'.format(\n",
    "        res,\n",
    "        bcubes(wl, 'cogid', res, pprint=False)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see, that the \"infomap\" method is, in fact, working one point better than the normal \"lexstat\" method, and you can also see how deep the difference between the correspondence-informed methods and the other methods is. As a last way to inspect the data, we will now use the `diff` function to create a file that contrasts the expert cognate sets with the ones inferred by Infomap (```$ python3 autocogs.py diff``` in terminal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: above, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t…¢u îa  \t   1\t   1\n",
      "Hawaiian_52      \ti_luna\t   1\t   1\n",
      "Mangareva_239    \tru≈ãa  \t   1\t   1\n",
      "Maori_85         \ti_ru≈ãa\t   1\t   1\n",
      "NorthMarquesan_38\t îuna  \t   1\t   1\n",
      "Rapanui_264      \truga  \t   1\t   1\n",
      "Tuamotuan_246    \tru≈ãa  \t   1\t   1\n",
      "Austral_128      \tnu îa  \t   1\t   2\n",
      "Tahitian_173     \tni îa  \t   1\t   2\n",
      "#\n",
      "Concept: all, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t îato îa    \t   1\t   1\n",
      "Austral_128      \tpaÀê îaÀêto îa\t   1\t   1\n",
      "Maori_85         \tkatoa     \t   1\t   1\n",
      "Sikaiana_243     \tkatoa     \t   1\t   1\n",
      "Tahitian_173     \tato îa     \t   1\t   1\n",
      "Tuamotuan_246    \tkato≈ãa    \t   1\t   1\n",
      "Hawaiian_52      \tapau      \t   3\t   3\n",
      "Mangareva_239    \tkouroa    \t   4\t   4\n",
      "NorthMarquesan_38\ttiatohu   \t   6\t   1\n",
      "Rapanui_264      \ttahi      \t   7\t   7\n",
      "#\n",
      "Concept: and, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \te   \t   1\t   1\n",
      "Austral_128      \t îeÀê \t   1\t   1\n",
      "Mangareva_239    \te   \t   1\t   1\n",
      "Tahitian_173     \t îeÀê \t   1\t   1\n",
      "Rapanui_264      \te   \t   1\t   1\n",
      "Maori_85         \tme  \t   3\t   1\n",
      "Hawaiian_52      \ta_me\t   3\t   3\n",
      "NorthMarquesan_38\tmaÀê \t   3\t   6\n",
      "Sikaiana_243     \tma  \t   3\t   6\n",
      "Rapanui_264      \tma  \t   3\t   6\n",
      "Maori_85         \thoki\t   5\t   5\n",
      "Rapanui_264      \tpiri\t   7\t   7\n",
      "Rapanui_264      \tpe  \t  11\t   1\n",
      "#\n",
      "Concept: ash, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t…¢ehu_auahi\t   1\t   1\n",
      "Austral_128      \tre îu      \t   1\t   1\n",
      "Hawaiian_52      \tlehu      \t   1\t   1\n",
      "Mangareva_239    \te îu       \t   1\t   1\n",
      "Maori_85         \tpu≈ãarehu  \t   1\t   1\n",
      "NorthMarquesan_38\t îehu      \t   1\t   1\n",
      "Sikaiana_243     \tlehu      \t   1\t   1\n",
      "Tahitian_173     \trehu      \t   1\t   1\n",
      "Tuamotuan_246    \trehu      \t   1\t   1\n",
      "Rapanui_264      \t îeo îeo    \t   1\t   7\n",
      "Mangareva_239    \t≈ãara îu    \t  11\t   1\n",
      "#\n",
      "Concept: at, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ti  \t   1\t   1\n",
      "Austral_128      \ti  \t   1\t   1\n",
      "Hawaiian_52      \ti  \t   1\t   1\n",
      "Mangareva_239    \tki \t   1\t   1\n",
      "NorthMarquesan_38\ti  \t   1\t   1\n",
      "Rapanui_264      \ti  \t   1\t   1\n",
      "Sikaiana_243     \ti  \t   1\t   1\n",
      "Tahitian_173     \ti  \t   1\t   1\n",
      "Tuamotuan_246    \ti  \t   1\t   1\n",
      "Maori_85         \ti  \t   1\t   1\n",
      "Maori_85         \thei\t   5\t   5\n",
      "Tuamotuan_246    \ttei\t   5\t  13\n",
      "Hawaiian_52      \tma \t  11\t  11\n",
      "#\n",
      "Concept: back, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ttua     \t   1\t   1\n",
      "Austral_128      \ttautua  \t   1\t   1\n",
      "Hawaiian_52      \tkua     \t   1\t   1\n",
      "Mangareva_239    \ttua     \t   1\t   1\n",
      "Maori_85         \ttuaraÀê  \t   1\t   1\n",
      "NorthMarquesan_38\ttua     \t   1\t   1\n",
      "Sikaiana_243     \ttua     \t   1\t   1\n",
      "Tahitian_173     \ttua     \t   1\t   1\n",
      "Rapanui_264      \ttu îa_ivi\t   1\t   7\n",
      "Tuamotuan_246    \tpapatua \t   1\t  10\n",
      "#\n",
      "Concept: bad, evil, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îino        \t   1\t   1\n",
      "Hawaiian_52      \t îino        \t   1\t   1\n",
      "Mangareva_239    \tkino        \t   1\t   1\n",
      "Maori_85         \tkino        \t   1\t   1\n",
      "Rapanui_264      \tkino        \t   1\t   1\n",
      "Tahitian_173     \t îino        \t   1\t   1\n",
      "Tuamotuan_246    \tkiro        \t   1\t   1\n",
      "Austral_128      \t îino        \t   1\t   1\n",
      "NorthMarquesan_38\t îino        \t   1\t   1\n",
      "Sikaiana_243     \thakakinokino\t   1\t   8\n",
      "Austral_128      \tmanuenu     \t   2\t   2\n",
      "NorthMarquesan_38\thauhau      \t   6\t   6\n",
      "#\n",
      "Concept: branch, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îaÀêmama_…¢aÀê îau\t   1\t   1\n",
      "Austral_128      \t îaÀêma îa       \t   1\t   2\n",
      "Maori_85         \tma≈ãa          \t   1\t   2\n",
      "Rapanui_264      \tmaga          \t   1\t   2\n",
      "Tahitian_173     \t îaÀêma îa       \t   1\t   2\n",
      "NorthMarquesan_38\t îa îa          \t   3\t   2\n",
      "Hawaiian_52      \tlaÀêlaÀê        \t   3\t   3\n",
      "Mangareva_239    \trara          \t   3\t   3\n",
      "Sikaiana_243     \tlaÀê           \t   3\t   3\n",
      "Tuamotuan_246    \traÀêkau        \t   3\t   3\n",
      "#\n",
      "Concept: child, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttama…¢i îi \t   1\t   1\n",
      "Maori_85         \ttamaiti  \t   1\t   1\n",
      "NorthMarquesan_38\ttama     \t   1\t   1\n",
      "Sikaiana_243     \ttamaliki \t   1\t   1\n",
      "Tahitian_173     \ttamari îi \t   1\t   1\n",
      "Tuamotuan_246    \ttamaÀêriki\t   1\t   1\n",
      "Austral_128      \ttamari îi \t   1\t   1\n",
      "Tuamotuan_246    \ttama     \t   1\t   1\n",
      "Austral_128      \tma îuru   \t   2\t   2\n",
      "Hawaiian_52      \tkeiki    \t   3\t   3\n",
      "Mangareva_239    \ttoromiki \t   4\t   1\n",
      "Rapanui_264      \tpoki     \t   7\t   7\n",
      "#\n",
      "Concept: cloud, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tata   \t   1\t   1\n",
      "Austral_128      \tata   \t   2\t   1\n",
      "Hawaiian_52      \tao    \t   3\t   3\n",
      "Mangareva_239    \tao    \t   3\t   3\n",
      "NorthMarquesan_38\tao    \t   3\t   3\n",
      "Tuamotuan_246    \tao    \t   3\t   3\n",
      "Maori_85         \tkapua \t   3\t   5\n",
      "Rapanui_264      \tragi  \t   7\t   7\n",
      "Sikaiana_243     \tlehuna\t   8\t   8\n",
      "Tahitian_173     \tata   \t   9\t   1\n",
      "Tuamotuan_246    \ttiti  \t  10\t  10\n",
      "Rapanui_264      \tkohu  \t  11\t  11\n",
      "#\n",
      "Concept: correct, true, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tmau      \t   1\t   1\n",
      "Mangareva_239    \tmau      \t   1\t   1\n",
      "Austral_128      \tparau_mau\t   1\t   2\n",
      "Hawaiian_52      \t îoiaÀê îi îo\t   3\t   3\n",
      "Mangareva_239    \ttika     \t   4\t   4\n",
      "Maori_85         \ttika     \t   4\t   4\n",
      "Rapanui_264      \ttitika   \t   4\t   4\n",
      "Tuamotuan_246    \ttika     \t   4\t   4\n",
      "NorthMarquesan_38\tmea_hei  \t   6\t   6\n",
      "Sikaiana_243     \ttonu     \t   8\t   8\n",
      "Tahitian_173     \ttano     \t   8\t   8\n",
      "Tahitian_173     \t îaÀêfaro  \t   9\t   9\n",
      "Austral_128      \t îaÀêfaro  \t   9\t   9\n",
      "NorthMarquesan_38\ttoitoi   \t  13\t  13\n",
      "Austral_128      \ttano     \t  15\t   8\n",
      "#\n",
      "Concept: dirty, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t…¢epo    \t   1\t   1\n",
      "Austral_128      \trepo    \t   1\t   1\n",
      "Hawaiian_52      \tlepo    \t   1\t   1\n",
      "Tahitian_173     \trepo    \t   1\t   1\n",
      "Mangareva_239    \tpaneu   \t   4\t   4\n",
      "Maori_85         \tparu    \t   5\t   5\n",
      "NorthMarquesan_38\tpa îapa îa\t   5\t  11\n",
      "Sikaiana_243     \tpela    \t   5\t  13\n",
      "NorthMarquesan_38\thava    \t   6\t   6\n",
      "Sikaiana_243     \tsava    \t   6\t   6\n",
      "Tuamotuan_246    \thava    \t   6\t   6\n",
      "Rapanui_264      \thava    \t   6\t   6\n",
      "Rapanui_264      \tone     \t   7\t   7\n",
      "#\n",
      "Concept: dull, blunt, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tpapa   \t   1\t   1\n",
      "Austral_128      \tmania  \t   2\t   2\n",
      "Tahitian_173     \tmania  \t   2\t   2\n",
      "Hawaiian_52      \tmuÀêmuÀê \t   3\t   3\n",
      "Austral_128      \ttuÀêmuÀê \t   3\t   3\n",
      "NorthMarquesan_38\ttumu îe \t   3\t   3\n",
      "Tuamotuan_246    \ttiÀê    \t   3\t  10\n",
      "Mangareva_239    \tmoimoi \t   4\t   4\n",
      "Maori_85         \tpuÀêhuki\t   5\t   5\n",
      "NorthMarquesan_38\tpuriki \t   5\t   6\n",
      "Rapanui_264      \tpuni   \t   7\t   7\n",
      "Sikaiana_243     \tmatapuÀê\t   7\t   8\n",
      "#\n",
      "Concept: dust, False Positives: yes, False Negatives: yes\n",
      "Austral_128      \t îu îa îu îa  \t   1\t   1\n",
      "Tahitian_173     \thu îahuaÀê  \t   1\t   1\n",
      "Hawaiian_52      \t îe îa      \t   1\t   2\n",
      "NorthMarquesan_38\t îepo      \t   1\t   5\n",
      "Mangareva_239    \te îu       \t   3\t   2\n",
      "Maori_85         \tpuehu     \t   3\t   2\n",
      "Rapanui_264      \tpugaehu   \t   3\t   2\n",
      "Sikaiana_243     \tlehu      \t   3\t   2\n",
      "Tuamotuan_246    \tpuÀêehu    \t   3\t   2\n",
      "Hawaiian_52      \t îehu      \t   3\t   2\n",
      "Mangareva_239    \tpu îeu     \t   3\t   2\n",
      "Rapanui_264      \tgarahu    \t   3\t  12\n",
      "Tahitian_173     \trepo_puehu\t   3\t  13\n",
      "Rapanui_264      \thuga      \t  14\t  14\n",
      "#\n",
      "Concept: egg, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \thue…¢o      \t   1\t   1\n",
      "Tahitian_173     \thoÀêro      \t   1\t   9\n",
      "Austral_128      \t îua        \t   2\t   2\n",
      "Hawaiian_52      \thua        \t   2\t   2\n",
      "Maori_85         \thua_manu   \t   2\t   5\n",
      "Mangareva_239    \tmaÀêmari_moa\t   4\t   4\n",
      "NorthMarquesan_38\tmama îi     \t   4\t   4\n",
      "Rapanui_264      \tm îaÀêmari   \t   4\t   4\n",
      "Sikaiana_243     \ttamamoa    \t   8\t   8\n",
      "Tuamotuan_246    \ttoÀêuo      \t  10\t  10\n",
      "Rapanui_264      \ttoua       \t  10\t  10\n",
      "Maori_85         \theÀêki      \t  11\t  11\n",
      "#\n",
      "Concept: father, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmetua_taÀêne\t   1\t   1\n",
      "Austral_128      \tmetua_taÀêne\t   1\t   1\n",
      "Hawaiian_52      \tmakua_kaÀêne\t   1\t   1\n",
      "Tahitian_173     \tmetua_taÀêne\t   1\t   1\n",
      "Tuamotuan_246    \tmetua_taÀêne\t   1\t   1\n",
      "Mangareva_239    \ttinana     \t   1\t   4\n",
      "Sikaiana_243     \ttamana     \t   1\t   4\n",
      "Maori_85         \tmatua      \t   1\t   5\n",
      "NorthMarquesan_38\tmotua      \t   1\t   5\n",
      "Rapanui_264      \tmatu îa     \t   1\t   5\n",
      "Rapanui_264      \tkoro       \t   7\t   7\n",
      "Austral_128      \tpaÀêpaÀê     \t  11\t  11\n",
      "Tahitian_173     \tpaÀêpaÀê     \t  11\t  11\n",
      "#\n",
      "Concept: fog, False Positives: no, False Negatives: yes\n",
      "Austral_128      \ta îinavai\t   1\t   1\n",
      "Hawaiian_52      \t îohu    \t   2\t   2\n",
      "Mangareva_239    \tko îu    \t   2\t   2\n",
      "Maori_85         \tkohu    \t   2\t   2\n",
      "NorthMarquesan_38\tkohu    \t   2\t   2\n",
      "Rapanui_264      \tkohu    \t   2\t   2\n",
      "Sikaiana_243     \tkohu    \t   2\t   2\n",
      "Tuamotuan_246    \tkohu    \t   2\t   2\n",
      "Rapanui_264      \tkapua   \t   2\t  10\n",
      "Tahitian_173     \truÀêpehu \t   8\t   8\n",
      "Tuamotuan_246    \tmaÀêhu   \t   9\t   9\n",
      "#\n",
      "Concept: fruit, False Positives: yes, False Negatives: no\n",
      "Austral_128      \tmaÀê îa\t   1\t   1\n",
      "Hawaiian_52      \thua  \t   2\t   2\n",
      "Mangareva_239    \t îua  \t   2\t   2\n",
      "Maori_85         \thua  \t   2\t   2\n",
      "NorthMarquesan_38\thua  \t   2\t   2\n",
      "Sikaiana_243     \thua  \t   2\t   2\n",
      "Tuamotuan_246    \thua  \t   2\t   2\n",
      "Rapanui_264      \tkai  \t   6\t   6\n",
      "Tahitian_173     \tmaÀê îa\t   8\t   1\n",
      "#\n",
      "Concept: good, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tmaita îi  \t   1\t   1\n",
      "Austral_128      \tmaita îi  \t   1\t   1\n",
      "Hawaiian_52      \tmaika îi  \t   1\t   1\n",
      "Tahitian_173     \tmaita îi  \t   1\t   1\n",
      "NorthMarquesan_38\tmeita îi  \t   1\t   1\n",
      "Tuamotuan_246    \tmeitaki  \t   1\t   1\n",
      "Mangareva_239    \tmeitetaki\t   4\t   1\n",
      "Maori_85         \tpai      \t   5\t   5\n",
      "NorthMarquesan_38\tkanahau  \t   6\t   6\n",
      "Rapanui_264      \trivariva \t   7\t   7\n",
      "Sikaiana_243     \tleka     \t   8\t   8\n",
      "Tuamotuan_246    \treka     \t   8\t   8\n",
      "Rapanui_264      \treka     \t   8\t   8\n",
      "NorthMarquesan_38\t îeka     \t   8\t   8\n",
      "Mangareva_239    \tporotu   \t  11\t  11\n",
      "#\n",
      "Concept: green, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tmatie     \t   1\t   1\n",
      "Austral_128      \tmatie     \t   1\t   1\n",
      "Rapanui_264      \tmata      \t   1\t   1\n",
      "Sikaiana_243     \tmoto      \t   1\t   1\n",
      "Tuamotuan_246    \tmatie     \t   1\t   1\n",
      "Tahitian_173     \tmatie     \t   1\t   1\n",
      "Hawaiian_52      \tma îoma îo  \t   3\t   3\n",
      "Mangareva_239    \tmoto      \t   4\t   1\n",
      "Maori_85         \tkaÀêkaÀêriki\t   5\t   5\n",
      "NorthMarquesan_38\t îoutite îe \t   6\t   6\n",
      "Tahitian_173     \tniÀênamu   \t   9\t   9\n",
      "#\n",
      "Concept: hair, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \thu…¢uhu…¢u_po îo\t   1\t   1\n",
      "NorthMarquesan_38\thu îu         \t   1\t   1\n",
      "Rapanui_264      \thuruhuru     \t   1\t   1\n",
      "Tuamotuan_246    \thuru         \t   1\t   1\n",
      "Austral_128      \trouru        \t   2\t   1\n",
      "Sikaiana_243     \tlaulu        \t   2\t   1\n",
      "Tahitian_173     \trouru        \t   2\t   1\n",
      "Tuamotuan_246    \troÀêuru       \t   2\t   1\n",
      "Hawaiian_52      \tlauoho       \t   2\t   3\n",
      "Mangareva_239    \trauo îo       \t   2\t   3\n",
      "NorthMarquesan_38\t îouoho       \t   2\t   3\n",
      "Maori_85         \tmakawe       \t   5\t   5\n",
      "Rapanui_264      \toho          \t   7\t   3\n",
      "#\n",
      "Concept: he/she, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îoia \t   1\t   1\n",
      "Austral_128      \t îoia \t   1\t   1\n",
      "Mangareva_239    \tkoia \t   1\t   1\n",
      "Hawaiian_52      \tia   \t   1\t   3\n",
      "Maori_85         \tia   \t   1\t   3\n",
      "NorthMarquesan_38\tia   \t   1\t   3\n",
      "Rapanui_264      \tia   \t   1\t   3\n",
      "Sikaiana_243     \tia   \t   1\t   3\n",
      "Tuamotuan_246    \tia   \t   1\t   3\n",
      "Tahitian_173     \t îoÀêna\t   9\t   9\n",
      "Austral_1213     \t îoÀêna\t   9\t   9\n",
      "Austral_128      \t îoÀêna\t   9\t   9\n",
      "#\n",
      "Concept: head, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tupo îo\t   1\t   1\n",
      "Hawaiian_52      \tpo îo \t   1\t   1\n",
      "Maori_85         \tupoko\t   1\t   1\n",
      "NorthMarquesan_38\tupoko\t   1\t   1\n",
      "Rapanui_264      \tpuoko\t   1\t   1\n",
      "Sikaiana_243     \tpoho \t   1\t   1\n",
      "Tahitian_173     \tupo îo\t   1\t   1\n",
      "Tuamotuan_246    \tupoko\t   1\t   1\n",
      "Austral_128      \tupo îo\t   1\t   1\n",
      "Mangareva_239    \tupoko\t   1\t   1\n",
      "Austral_128      \tpao  \t   2\t   1\n",
      "Mangareva_239    \to îo  \t   4\t   1\n",
      "NorthMarquesan_38\tu îu  \t  13\t  13\n",
      "Tuamotuan_246    \turu  \t  13\t  13\n",
      "#\n",
      "Concept: heavy, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttoimaha \t   1\t   1\n",
      "Austral_128      \ttia îa   \t   1\t   1\n",
      "Hawaiian_52      \tkaumaha \t   1\t   1\n",
      "Maori_85         \ttaimaha \t   1\t   1\n",
      "Sikaiana_243     \tmmaha   \t   1\t   1\n",
      "Tahitian_173     \ttoiaha  \t   1\t   1\n",
      "Mangareva_239    \tteimaha \t   1\t   1\n",
      "Mangareva_239    \tkikikiki\t   4\t   4\n",
      "NorthMarquesan_38\ttoko    \t   6\t   6\n",
      "Rapanui_264      \tpagaha îa\t   7\t   7\n",
      "Tuamotuan_246    \ttu îatu îa\t  10\t  10\n",
      "NorthMarquesan_38\ttono    \t  12\t   6\n",
      "#\n",
      "Concept: how?, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tnaÀê_hea\t   1\t   1\n",
      "Austral_128      \tnaÀê îea \t   1\t   2\n",
      "Tahitian_173     \tnaÀêfea \t   1\t   2\n",
      "Hawaiian_52      \tpehea  \t   1\t   3\n",
      "Mangareva_239    \tpe îea  \t   1\t   3\n",
      "Maori_85         \tpeÀêhea \t   1\t   3\n",
      "NorthMarquesan_38\tpeÀêhea \t   1\t   3\n",
      "Sikaiana_243     \tpehea  \t   1\t   3\n",
      "Rapanui_264      \tpe_h îe \t   1\t   7\n",
      "#\n",
      "Concept: husband, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttaÀêne \t   1\t   1\n",
      "Austral_128      \ttaÀêne \t   1\t   1\n",
      "Hawaiian_52      \tkaÀêne \t   1\t   1\n",
      "Maori_85         \ttaÀêne \t   1\t   1\n",
      "Tahitian_173     \ttaÀêne \t   1\t   1\n",
      "Tuamotuan_246    \ttaÀêne \t   1\t   1\n",
      "Mangareva_239    \ta îana \t   4\t   4\n",
      "NorthMarquesan_38\thahana\t   6\t   4\n",
      "Mangareva_239    \tahana \t   6\t   4\n",
      "Rapanui_264      \tkenu  \t   7\t   7\n",
      "#\n",
      "Concept: I, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tvau\t   1\t   1\n",
      "Austral_128      \tau \t   1\t   1\n",
      "Hawaiian_52      \tau \t   1\t   1\n",
      "Mangareva_239    \tau \t   1\t   1\n",
      "Maori_85         \tau \t   1\t   1\n",
      "Rapanui_264      \tau \t   1\t   1\n",
      "Sikaiana_243     \tau \t   1\t   1\n",
      "Tahitian_173     \tvau\t   1\t   1\n",
      "Austral_128      \tvau\t   1\t   1\n",
      "NorthMarquesan_38\tau \t   1\t   1\n",
      "Tahitian_173     \tau \t   1\t   1\n",
      "Tuamotuan_246    \tau \t   1\t   1\n",
      "NorthMarquesan_38\t îu \t   6\t   6\n",
      "Tuamotuan_246    \tku \t   6\t  10\n",
      "#\n",
      "Concept: if, False Positives: yes, False Negatives: no\n",
      "Austral_128      \tmai_te_pa îau\t   1\t   1\n",
      "Hawaiian_52      \tinaÀê        \t   2\t   2\n",
      "Sikaiana_243     \thano        \t   2\t   2\n",
      "Maori_85         \tme          \t   3\t   3\n",
      "NorthMarquesan_38\tme          \t   3\t   3\n",
      "Rapanui_264      \tana         \t   5\t   2\n",
      "Sikaiana_243     \tpela        \t   6\t   6\n",
      "Tahitian_173     \t îia         \t   7\t   7\n",
      "Austral_128      \t îa îiri      \t   8\t   8\n",
      "#\n",
      "Concept: intestines, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îavi…¢i\t   1\t   1\n",
      "Austral_128      \t îaÀê îau\t   2\t   2\n",
      "Hawaiian_52      \tna îau \t   2\t   2\n",
      "Tahitian_173     \t îaÀê îau\t   2\t   2\n",
      "Tuamotuan_246    \t≈ãaÀêkau\t   2\t   2\n",
      "Maori_85         \tfeÀêkau\t   2\t   5\n",
      "Sikaiana_243     \tkautae\t   2\t   8\n",
      "Mangareva_239    \tmanava\t   4\t   4\n",
      "NorthMarquesan_38\tkoekoe\t   6\t   6\n",
      "Rapanui_264      \tkokoma\t   6\t   7\n",
      "#\n",
      "Concept: lake, False Positives: no, False Negatives: yes\n",
      "Austral_128      \troto    \t   1\t   1\n",
      "Hawaiian_52      \tloko    \t   1\t   1\n",
      "Maori_85         \troto    \t   1\t   1\n",
      "Tahitian_173     \troto    \t   1\t   1\n",
      "Tuamotuan_246    \troto    \t   1\t   1\n",
      "NorthMarquesan_38\tvai_ îoto\t   1\t   5\n",
      "Mangareva_239    \trano    \t   3\t   3\n",
      "Rapanui_264      \trano    \t   3\t   3\n",
      "Tuamotuan_246    \trano    \t   3\t   3\n",
      "#\n",
      "Concept: leaf, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t…¢aue…¢e \t   1\t   1\n",
      "Austral_128      \trau îere\t   1\t   1\n",
      "Tahitian_173     \trau îere\t   1\t   1\n",
      "Hawaiian_52      \tlau    \t   1\t   3\n",
      "Mangareva_239    \trau    \t   1\t   3\n",
      "Maori_85         \trau    \t   1\t   3\n",
      "NorthMarquesan_38\t îau    \t   1\t   3\n",
      "Rapanui_264      \traup îa \t   1\t   3\n",
      "Sikaiana_243     \tlau    \t   1\t   3\n",
      "Tuamotuan_246    \trau    \t   1\t   3\n",
      "#\n",
      "Concept: long, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t…¢oa\t   1\t   1\n",
      "Austral_128      \troa\t   1\t   1\n",
      "Hawaiian_52      \tloa\t   1\t   1\n",
      "Maori_85         \troa\t   1\t   1\n",
      "NorthMarquesan_38\t îoa\t   1\t   1\n",
      "Rapanui_264      \troa\t   1\t   1\n",
      "Sikaiana_243     \tloa\t   1\t   1\n",
      "Tahitian_173     \troa\t   1\t   1\n",
      "Tuamotuan_246    \troa\t   1\t   1\n",
      "Mangareva_239    \troa\t   4\t   1\n",
      "#\n",
      "Concept: man/male, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttaÀêne   \t   1\t   1\n",
      "Austral_128      \ttaÀêne   \t   1\t   1\n",
      "Hawaiian_52      \tkaÀêne   \t   1\t   1\n",
      "Maori_85         \ttaÀêne   \t   1\t   1\n",
      "Rapanui_264      \ttane    \t   1\t   1\n",
      "Tahitian_173     \ttaÀêne   \t   1\t   1\n",
      "Tuamotuan_246    \ttaÀêne   \t   1\t   1\n",
      "Sikaiana_243     \ttaÀêne   \t   1\t   1\n",
      "NorthMarquesan_38\ttane    \t   1\t   1\n",
      "Mangareva_239    \tta≈ãata  \t   4\t   1\n",
      "Sikaiana_243     \ttanata  \t   4\t   1\n",
      "NorthMarquesan_38\ttoa     \t   6\t   6\n",
      "Mangareva_239    \ttamaroa \t   6\t  11\n",
      "NorthMarquesan_38\theko    \t  12\t  12\n",
      "Tuamotuan_246    \thaÀêkoi  \t  12\t  12\n",
      "NorthMarquesan_38\ttama_ îoa\t  16\t  16\n",
      "#\n",
      "Concept: meat/flesh, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îi îo   \t   1\t   1\n",
      "Hawaiian_52      \t îi îo   \t   1\t   1\n",
      "Mangareva_239    \tkiko   \t   1\t   1\n",
      "Maori_85         \tkiko   \t   1\t   1\n",
      "NorthMarquesan_38\tkiko   \t   1\t   1\n",
      "Rapanui_264      \tkiko   \t   1\t   1\n",
      "Tahitian_173     \t îi îo   \t   1\t   1\n",
      "Tuamotuan_246    \tkiko   \t   1\t   1\n",
      "Austral_128      \t îi îo   \t   1\t   1\n",
      "Sikaiana_243     \tio     \t   1\t   8\n",
      "Austral_128      \t îiÀêna îi\t   2\t   2\n",
      "#\n",
      "Concept: moon, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îaÀêva îe\t   1\t   1\n",
      "Austral_128      \t îaÀêva îe\t   1\t   1\n",
      "Tahitian_173     \t îaÀêva îe\t   1\t   1\n",
      "Hawaiian_52      \tmahina \t   3\t   3\n",
      "Mangareva_239    \tma îina \t   3\t   3\n",
      "Rapanui_264      \tmahina \t   3\t   3\n",
      "Tuamotuan_246    \thina   \t   3\t   3\n",
      "Mangareva_239    \tmaÀê îina\t   3\t   3\n",
      "NorthMarquesan_38\tme îama \t   3\t   5\n",
      "Maori_85         \tmarama \t   5\t   5\n",
      "Sikaiana_243     \tmalama \t   5\t   5\n",
      "#\n",
      "Concept: mosquito, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tnaonao      \t   1\t   1\n",
      "Rapanui_264      \tna îona îo    \t   1\t   1\n",
      "Tahitian_173     \tnaonao      \t   1\t   1\n",
      "Austral_128      \tramu        \t   1\t   2\n",
      "Sikaiana_243     \tnamu        \t   1\t   2\n",
      "Tuamotuan_246    \tnamu        \t   1\t   2\n",
      "NorthMarquesan_38\tnono_purutia\t   1\t   6\n",
      "Hawaiian_52      \tmakika      \t   3\t   3\n",
      "Mangareva_239    \tkoÀêmanu     \t   4\t   4\n",
      "Maori_85         \twaeroa      \t   5\t   5\n",
      "#\n",
      "Concept: mother, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmetua_vahine\t   1\t   1\n",
      "Austral_128      \tmetua_va îine\t   1\t   1\n",
      "Tahitian_173     \tmetua_vahine\t   1\t   1\n",
      "Tuamotuan_246    \tmetua_vahine\t   1\t   1\n",
      "Hawaiian_52      \tmakuahine   \t   1\t   3\n",
      "Rapanui_264      \tmatu îa      \t   1\t   7\n",
      "Mangareva_239    \ttinana      \t   4\t   4\n",
      "Sikaiana_243     \ttinna       \t   4\t   4\n",
      "Maori_85         \tfaea        \t   5\t   5\n",
      "NorthMarquesan_38\tkui         \t   6\t   6\n",
      "Austral_128      \tmaÀêmaÀê      \t  11\t  11\n",
      "Tahitian_173     \tmaÀêmaÀê      \t  11\t  11\n",
      "#\n",
      "Concept: narrow, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \toaoa    \t   1\t   1\n",
      "Austral_128      \toaoa    \t   1\t   1\n",
      "Tahitian_173     \toaoa    \t   1\t   1\n",
      "Hawaiian_52      \tlaÀê îiki \t   3\t   3\n",
      "Mangareva_239    \taÀêiti   \t   3\t   4\n",
      "Maori_85         \tfaÀêiti  \t   3\t   4\n",
      "NorthMarquesan_38\tfaiti   \t   3\t   4\n",
      "Rapanui_264      \trikiriki\t   3\t  12\n",
      "Rapanui_264      \tvakavaka\t   7\t   7\n",
      "Sikaiana_243     \tkopiti  \t   8\t   4\n",
      "Tuamotuan_246    \tkoma    \t  10\t  10\n",
      "Austral_128      \tpiri    \t  11\t  11\n",
      "#\n",
      "Concept: needle, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tnira\t   1\t   1\n",
      "Austral_128      \tnira\t   1\t   1\n",
      "Maori_85         \t≈ãira\t   1\t   1\n",
      "Tahitian_173     \tnira\t   1\t   1\n",
      "NorthMarquesan_38\trira\t   1\t   6\n",
      "Hawaiian_52      \tkui \t   3\t   3\n",
      "Mangareva_239    \tnira\t   4\t   1\n",
      "Rapanui_264      \tivi \t   7\t   7\n",
      "Sikaiana_243     \tsika\t   8\t   8\n",
      "Rapanui_264      \thika\t   8\t   8\n",
      "Tuamotuan_246    \thau \t  10\t  10\n",
      "#\n",
      "Concept: no, not, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \te îere  \t   1\t   1\n",
      "Austral_128      \te_ îore \t   2\t   1\n",
      "Hawaiian_52      \t îole   \t   2\t   1\n",
      "Mangareva_239    \tkore   \t   2\t   1\n",
      "Maori_85         \tkaÀêhore\t   2\t   1\n",
      "NorthMarquesan_38\tteÀê    \t   6\t   6\n",
      "Sikaiana_243     \theai   \t   6\t   8\n",
      "Rapanui_264      \tina_kai\t   7\t   7\n",
      "Tahitian_173     \t îaita  \t   9\t   9\n",
      "Tuamotuan_246    \tkauraka\t  10\t  10\n",
      "NorthMarquesan_38\tieai   \t  11\t  11\n",
      "Rapanui_264      \tta îe   \t  12\t  12\n",
      "#\n",
      "Concept: nose, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tihu     \t   1\t   1\n",
      "Hawaiian_52      \tihu     \t   1\t   1\n",
      "Mangareva_239    \ti îu     \t   1\t   1\n",
      "Maori_85         \tihu     \t   1\t   1\n",
      "NorthMarquesan_38\tihu     \t   1\t   1\n",
      "Rapanui_264      \tihu     \t   1\t   1\n",
      "Sikaiana_243     \tkaiusu  \t   1\t   1\n",
      "Tahitian_173     \tihu     \t   1\t   1\n",
      "Tuamotuan_246    \tihu     \t   1\t   1\n",
      "Austral_128      \tputa_e îu\t   1\t   2\n",
      "#\n",
      "Concept: old, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttahito \t   1\t   1\n",
      "Hawaiian_52      \tkahiko \t   1\t   1\n",
      "Mangareva_239    \tte îito \t   1\t   1\n",
      "NorthMarquesan_38\ttehito \t   1\t   1\n",
      "Austral_128      \truÀê îau \t   2\t   2\n",
      "Tahitian_173     \truÀê îau \t   2\t   2\n",
      "Maori_85         \tpakeke \t   5\t   5\n",
      "Rapanui_264      \ttuai   \t   7\t   7\n",
      "Sikaiana_243     \tmatua  \t   8\t   7\n",
      "Tuamotuan_246    \tkorou  \t  10\t  10\n",
      "Rapanui_264      \tkorohua\t  10\t  10\n",
      "NorthMarquesan_38\tkoua   \t  10\t  11\n",
      "Sikaiana_243     \tmua    \t  13\t   7\n",
      "NorthMarquesan_38\tkakiu  \t  14\t  14\n",
      "#\n",
      "Concept: person/human being, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tta îata\t   1\t   1\n",
      "Austral_128      \tta îata\t   1\t   1\n",
      "Hawaiian_52      \tkanaka\t   1\t   1\n",
      "Mangareva_239    \tta≈ãata\t   1\t   1\n",
      "Maori_85         \tta≈ãata\t   1\t   1\n",
      "NorthMarquesan_38\t îenata\t   1\t   1\n",
      "Rapanui_264      \ttagata\t   1\t   1\n",
      "Tahitian_173     \tta îata\t   1\t   1\n",
      "Tuamotuan_246    \tta≈ãata\t   1\t   1\n",
      "NorthMarquesan_38\tkenana\t   1\t   1\n",
      "Sikaiana_243     \ttanata\t   1\t   1\n",
      "Sikaiana_243     \ttama  \t   8\t   1\n",
      "#\n",
      "Concept: rain, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tua  \t   1\t   1\n",
      "Austral_128      \tua  \t   2\t   1\n",
      "Hawaiian_52      \tua  \t   2\t   1\n",
      "Mangareva_239    \tua  \t   2\t   1\n",
      "Maori_85         \tua  \t   2\t   1\n",
      "NorthMarquesan_38\tua  \t   2\t   1\n",
      "Rapanui_264      \t îuÀêa\t   2\t   1\n",
      "Sikaiana_243     \tua  \t   2\t   1\n",
      "Tahitian_173     \tua  \t   2\t   1\n",
      "Tuamotuan_246    \tua  \t   2\t   1\n",
      "#\n",
      "Concept: red, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îute îute\t   1\t   1\n",
      "Tahitian_173     \t îute îute\t   1\t   1\n",
      "Austral_128      \t îura îura\t   2\t   2\n",
      "Hawaiian_52      \t îula    \t   2\t   2\n",
      "Mangareva_239    \tkura    \t   2\t   2\n",
      "Tuamotuan_246    \tkura    \t   2\t   2\n",
      "NorthMarquesan_38\tkuwa    \t   2\t  11\n",
      "Maori_85         \tfero    \t   5\t   5\n",
      "Rapanui_264      \therohero\t   5\t   7\n",
      "NorthMarquesan_38\tpukiki  \t   6\t   6\n",
      "Sikaiana_243     \tmea     \t   8\t   8\n",
      "Tuamotuan_246    \tmea     \t   8\t   8\n",
      "Rapanui_264      \tmea     \t   8\t   8\n",
      "#\n",
      "Concept: road/path, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tpu…¢umu   \t   1\t   1\n",
      "Austral_128      \tpuruÀêmu  \t   1\t   1\n",
      "Tahitian_173     \tpuruÀêmu  \t   1\t   1\n",
      "Austral_128      \tara îara îa\t   2\t   2\n",
      "Hawaiian_52      \tala      \t   2\t   3\n",
      "Mangareva_239    \tara      \t   2\t   3\n",
      "Maori_85         \tara      \t   2\t   3\n",
      "Rapanui_264      \tara      \t   2\t   3\n",
      "Sikaiana_243     \tala      \t   2\t   3\n",
      "Tahitian_173     \tara      \t   2\t   3\n",
      "Tuamotuan_246    \tara      \t   2\t   3\n",
      "NorthMarquesan_38\tva îa     \t   6\t   6\n",
      "Tahitian_173     \t îeÀê îa    \t  13\t  13\n",
      "#\n",
      "Concept: root, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ta îa     \t   1\t   1\n",
      "Austral_128      \ta îa     \t   1\t   1\n",
      "Hawaiian_52      \ta îa     \t   1\t   1\n",
      "Mangareva_239    \taka     \t   1\t   1\n",
      "NorthMarquesan_38\taka     \t   1\t   1\n",
      "Rapanui_264      \taka     \t   1\t   1\n",
      "Tahitian_173     \ta îa     \t   1\t   1\n",
      "Tuamotuan_246    \taka     \t   1\t   1\n",
      "Maori_85         \tpaki_aka\t   1\t   5\n",
      "Sikaiana_243     \tpatiaka \t   1\t   8\n",
      "#\n",
      "Concept: rotten, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \thenoheno\t   1\t   1\n",
      "Austral_128      \tpara    \t   2\t   2\n",
      "Mangareva_239    \tpara    \t   2\t   2\n",
      "Rapanui_264      \tpara    \t   2\t   2\n",
      "Sikaiana_243     \tpala    \t   2\t   2\n",
      "NorthMarquesan_38\tpa îa    \t   2\t   2\n",
      "Tuamotuan_246    \tpara    \t   2\t   2\n",
      "Hawaiian_52      \tpilau   \t   3\t   2\n",
      "Maori_85         \tpirau   \t   3\t   2\n",
      "NorthMarquesan_38\tpeÀê     \t   6\t   6\n",
      "Tahitian_173     \t îoÀêpeÀê  \t   6\t   9\n",
      "Tuamotuan_246    \tpopo    \t  10\t  10\n",
      "Mangareva_239    \tpopo    \t  10\t  10\n",
      "Sikaiana_243     \tpopo    \t  10\t  10\n",
      "#\n",
      "Concept: sharp, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îoi   \t   1\t   1\n",
      "Austral_128      \t îoi   \t   1\t   1\n",
      "Hawaiian_52      \t îoi   \t   1\t   1\n",
      "Mangareva_239    \tkoikoi\t   1\t   1\n",
      "Maori_85         \tkoi   \t   1\t   1\n",
      "NorthMarquesan_38\tkoi   \t   1\t   1\n",
      "Tahitian_173     \t îoi   \t   1\t   1\n",
      "Tuamotuan_246    \tkoi   \t   1\t   1\n",
      "Rapanui_264      \tka îi  \t   1\t   7\n",
      "Sikaiana_243     \tkaÀê   \t   1\t   7\n",
      "Tuamotuan_246    \tpopo  \t  10\t  10\n",
      "#\n",
      "Concept: shy, ashamed, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmaÀêmahu \t   1\t   1\n",
      "Tahitian_173     \tmaÀêmahu \t   1\t   1\n",
      "Austral_128      \t îa îamaÀê \t   1\t   2\n",
      "Mangareva_239    \t îakaÀêma \t   1\t   2\n",
      "Maori_85         \tfakamaÀê \t   1\t   2\n",
      "Rapanui_264      \thaÀê     \t   1\t   7\n",
      "Hawaiian_52      \thilahila\t   3\t   3\n",
      "NorthMarquesan_38\thakaika \t   6\t   6\n",
      "#\n",
      "Concept: smoke, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tau_auahi\t   1\t   1\n",
      "Austral_128      \tauaua îi \t   1\t   1\n",
      "Hawaiian_52      \tuahi    \t   1\t   1\n",
      "Mangareva_239    \tahi     \t   1\t   1\n",
      "Maori_85         \tauahi   \t   1\t   1\n",
      "NorthMarquesan_38\tauahi   \t   1\t   1\n",
      "Rapanui_264      \tauahi   \t   1\t   1\n",
      "Tahitian_173     \tauauahi \t   1\t   1\n",
      "Tuamotuan_246    \tauahi   \t   1\t   1\n",
      "Sikaiana_243     \tau      \t   1\t   8\n",
      "#\n",
      "Concept: spider, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ttu îunui      \t   1\t   1\n",
      "Tahitian_173     \ttuÀêtuÀêrahonui\t   1\t   1\n",
      "Rapanui_264      \th îoÀênu       \t   1\t   7\n",
      "Tuamotuan_246    \ttukutuku     \t   1\t  10\n",
      "Austral_128      \t îapuama îama îa\t   2\t   2\n",
      "Hawaiian_52      \tlanalana     \t   3\t   3\n",
      "Mangareva_239    \tpuÀê≈ãawerewere\t   4\t   4\n",
      "Maori_85         \tpu≈ãaÀêwerewere\t   4\t   4\n",
      "Sikaiana_243     \tvelevele     \t   4\t   4\n",
      "NorthMarquesan_38\tv îeev îee     \t   4\t   6\n",
      "#\n",
      "Concept: star, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \theti îa\t   1\t   1\n",
      "Austral_128      \tfeti îa\t   1\t   1\n",
      "Hawaiian_52      \thoÀêkuÀê\t   1\t   1\n",
      "Mangareva_239    \t îetu  \t   1\t   1\n",
      "Maori_85         \tfetuÀê \t   1\t   1\n",
      "Rapanui_264      \thetu îu\t   1\t   1\n",
      "Sikaiana_243     \thetuÀê \t   1\t   1\n",
      "Tahitian_173     \tfeti îa\t   1\t   1\n",
      "Tuamotuan_246    \thetuÀê \t   1\t   1\n",
      "NorthMarquesan_38\tfettoe\t   1\t   6\n",
      "#\n",
      "Concept: stone, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îohai     \t   1\t   1\n",
      "Tahitian_173     \t îoÀêfa îi   \t   1\t   1\n",
      "Austral_128      \t îoÀê îa îi   \t   1\t   1\n",
      "Austral_128      \tpo îatu    \t   2\t   2\n",
      "Hawaiian_52      \tpoÀêhaku   \t   2\t   2\n",
      "Mangareva_239    \tpo îatu    \t   2\t   2\n",
      "Maori_85         \tkoÀêfatu   \t   2\t   2\n",
      "Sikaiana_243     \thatu      \t   2\t   2\n",
      "Tuamotuan_246    \tpoÀêfatu   \t   2\t   2\n",
      "Tuamotuan_246    \thatu      \t   2\t   2\n",
      "NorthMarquesan_38\thatu+ke îaa\t   2\t  12\n",
      "NorthMarquesan_38\tke îa      \t   6\t   6\n",
      "Rapanui_264      \tma îea     \t   7\t   7\n",
      "#\n",
      "Concept: tail, False Positives: yes, False Negatives: yes\n",
      "Austral_128      \tvero   \t   1\t   1\n",
      "Hawaiian_52      \thuelo  \t   1\t   1\n",
      "NorthMarquesan_38\tv îeo   \t   1\t   1\n",
      "Tuamotuan_246    \tvaero  \t   1\t   1\n",
      "Mangareva_239    \tvero   \t   1\t   1\n",
      "Tahitian_173     \t îaero  \t   1\t   1\n",
      "Mangareva_239    \tave    \t   3\t   1\n",
      "Maori_85         \tfiore  \t   4\t   4\n",
      "Rapanui_264      \thiku   \t   6\t   6\n",
      "NorthMarquesan_38\thiku   \t   6\t   6\n",
      "Tahitian_173     \thi îu   \t   6\t   6\n",
      "Tuamotuan_246    \thiku   \t   6\t   6\n",
      "Mangareva_239    \t îiku   \t   6\t   6\n",
      "Austral_128      \t îu îu   \t   7\t   6\n",
      "Sikaiana_243     \tmuisuki\t   7\t   7\n",
      "Tahitian_173     \t îitere \t   8\t   8\n",
      "#\n",
      "Concept: Ten, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îahu…¢u  \t   1\t   1\n",
      "Austral_128      \t îa îuru  \t   1\t   1\n",
      "Mangareva_239    \tro≈ão îuru\t   1\t   1\n",
      "NorthMarquesan_38\t îokohu îu\t   1\t   1\n",
      "Tahitian_173     \t îahuru  \t   1\t   1\n",
      "Tuamotuan_246    \t≈ãahuru  \t   1\t   1\n",
      "Hawaiian_52      \tanahulu \t   1\t   1\n",
      "Maori_85         \tha≈ãahuru\t   1\t   1\n",
      "NorthMarquesan_38\t îonohu îu\t   1\t   1\n",
      "Rapanui_264      \ta≈ãahuru \t   1\t   1\n",
      "Hawaiian_52      \t îumi    \t   3\t   3\n",
      "Maori_85         \ttekau   \t   5\t   5\n",
      "Rapanui_264      \tkauatu  \t   5\t   7\n",
      "Sikaiana_243     \tsehui   \t   8\t   8\n",
      "#\n",
      "Concept: that, False Positives: yes, False Negatives: no\n",
      "Austral_128      \tteÀêraÀê\t   1\t   1\n",
      "Hawaiian_52      \tla    \t   2\t   2\n",
      "Maori_85         \tteÀêraÀê\t   3\t   1\n",
      "NorthMarquesan_38\tte îaÀê \t   4\t   1\n",
      "Hawaiian_52      \tna    \t   4\t   1\n",
      "Maori_85         \tteÀênaÀê\t   4\t   1\n",
      "Rapanui_264      \tera   \t   5\t   1\n",
      "Tahitian_173     \tteÀêraÀê\t   6\t   1\n",
      "Tuamotuan_246    \taua   \t   7\t   7\n",
      "#\n",
      "Concept: they, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t…¢aÀêtou\t   1\t   1\n",
      "Austral_128      \traÀêtou\t   1\t   1\n",
      "Hawaiian_52      \tlaÀêkou\t   1\t   1\n",
      "Maori_85         \traÀêtou\t   1\t   1\n",
      "NorthMarquesan_38\t îatou \t   1\t   1\n",
      "Tahitian_173     \traÀêtou\t   1\t   1\n",
      "Sikaiana_243     \tlaÀêtou\t   1\t   1\n",
      "Mangareva_239    \traÀêua \t   1\t   7\n",
      "Mangareva_239    \traÀêtou\t   4\t   1\n",
      "Rapanui_264      \tra îua \t   7\t   7\n",
      "Sikaiana_243     \tlaÀêua \t   7\t   7\n",
      "Austral_1213     \t…¢aÀêua \t   7\t   7\n",
      "Austral_128      \traÀêua \t   7\t   7\n",
      "Hawaiian_52      \tlaÀêua \t   7\t   7\n",
      "Maori_85         \traÀêua \t   7\t   7\n",
      "Tahitian_173     \traÀêua \t   7\t   7\n",
      "#\n",
      "Concept: thick, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tme îume îu   \t   1\t   1\n",
      "Tahitian_173     \tme îume îu   \t   1\t   1\n",
      "Austral_128      \ttuetue     \t   2\t   2\n",
      "Tuamotuan_246    \ttu îatu îa   \t   2\t  10\n",
      "Hawaiian_52      \tmaÀêkolukolu\t   3\t   3\n",
      "Mangareva_239    \tmaÀêtoru    \t   3\t   3\n",
      "Maori_85         \tmatotoru   \t   3\t   3\n",
      "NorthMarquesan_38\tmoto îu     \t   3\t   3\n",
      "Rapanui_264      \tmatoru     \t   3\t   3\n",
      "Sikaiana_243     \tmaÀêtoru    \t   3\t   3\n",
      "Rapanui_264      \teÀêpe       \t  11\t  11\n",
      "#\n",
      "Concept: thin, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t…¢ai…¢ai    \t   1\t   1\n",
      "Austral_128      \trairai    \t   1\t   1\n",
      "Hawaiian_52      \tlahi      \t   1\t   1\n",
      "Maori_85         \trahirahi  \t   1\t   1\n",
      "Rapanui_264      \tra îi      \t   1\t   1\n",
      "Tahitian_173     \trairai    \t   1\t   1\n",
      "Tuamotuan_246    \trahi      \t   1\t   1\n",
      "NorthMarquesan_38\tpi îahi îahi\t   1\t   1\n",
      "Mangareva_239    \trikiriki  \t   4\t   4\n",
      "NorthMarquesan_38\tkahikahi  \t   6\t   1\n",
      "Sikaiana_243     \ttualiki   \t   8\t   8\n",
      "NorthMarquesan_38\t îakiaki   \t  12\t  12\n",
      "#\n",
      "Concept: this, False Positives: yes, False Negatives: yes\n",
      "Austral_128      \tteie  \t   1\t   1\n",
      "Hawaiian_52      \tkeÀêia \t   2\t   1\n",
      "Mangareva_239    \ttenei \t   3\t   3\n",
      "Maori_85         \tteÀênei\t   3\t   3\n",
      "NorthMarquesan_38\ttenei \t   3\t   3\n",
      "Sikaiana_243     \tte_nei\t   3\t   7\n",
      "Rapanui_264      \tnei   \t   6\t   3\n",
      "Hawaiian_52      \tnei   \t   6\t   3\n",
      "Tahitian_173     \tteie  \t   8\t   1\n",
      "Tuamotuan_246    \tte    \t   9\t   1\n",
      "#\n",
      "Concept: thou, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t îoe  \t   1\t   1\n",
      "Austral_128      \t îoe  \t   1\t   1\n",
      "Hawaiian_52      \t îoe  \t   1\t   1\n",
      "Mangareva_239    \tkoe  \t   1\t   1\n",
      "Maori_85         \tkoe  \t   1\t   1\n",
      "Rapanui_264      \tkou  \t   1\t   1\n",
      "Sikaiana_243     \tkoe  \t   1\t   1\n",
      "Tahitian_173     \t îoe  \t   1\t   1\n",
      "Tuamotuan_246    \tkoe  \t   1\t   1\n",
      "NorthMarquesan_38\t îoe  \t   1\t   1\n",
      "NorthMarquesan_38\tko îua\t   6\t   1\n",
      "#\n",
      "Concept: thunder, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tpaÀêti…¢i    \t   1\t   1\n",
      "Austral_128      \tpaÀêtiri    \t   1\t   1\n",
      "Mangareva_239    \tatutiri    \t   1\t   1\n",
      "Maori_85         \tfatitiri   \t   1\t   1\n",
      "Rapanui_264      \tpatiri     \t   1\t   1\n",
      "Tahitian_173     \tpaÀêtiri    \t   1\t   1\n",
      "Tuamotuan_246    \tfatutiri   \t   1\t   1\n",
      "Hawaiian_52      \thekili     \t   1\t   3\n",
      "NorthMarquesan_38\tpha_toÀê_teÀê\t   1\t   6\n",
      "Sikaiana_243     \tmana       \t   8\t   8\n",
      "#\n",
      "Concept: to bite, False Positives: no, False Negatives: yes\n",
      "Austral_128      \t îoÀê îini îini\t   1\t   1\n",
      "Tahitian_173     \thohoni     \t   1\t   1\n",
      "Hawaiian_52      \tnahu       \t   2\t   2\n",
      "Maori_85         \t≈ãau        \t   2\t   2\n",
      "NorthMarquesan_38\tnahu       \t   2\t   2\n",
      "Rapanui_264      \tgau        \t   2\t   2\n",
      "Mangareva_239    \teti        \t   3\t   3\n",
      "Tuamotuan_246    \tkati       \t   3\t   9\n",
      "Austral_128      \tpa îati     \t   3\t   9\n",
      "Sikaiana_243     \tnunu       \t   7\t   7\n",
      "#\n",
      "Concept: to breathe, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \thuti_te_aho  \t   1\t   1\n",
      "Austral_128      \t îuti_i_te_a îo\t   1\t   1\n",
      "Tahitian_173     \thuti_i_te_aho\t   1\t   1\n",
      "Hawaiian_52      \taho          \t   1\t  11\n",
      "Hawaiian_52      \thanu         \t   3\t   3\n",
      "Rapanui_264      \thaÀê          \t   3\t   3\n",
      "NorthMarquesan_38\tha           \t   3\t   3\n",
      "Maori_85         \tfakataÀê      \t   3\t   5\n",
      "Mangareva_239    \t îau          \t   4\t   3\n",
      "NorthMarquesan_38\tmenava       \t   6\t   6\n",
      "Sikaiana_243     \tmaÀênava      \t   6\t   6\n",
      "Tuamotuan_246    \tmanava       \t   6\t   6\n",
      "Tuamotuan_246    \t≈ãaÀê          \t  13\t  13\n",
      "#\n",
      "Concept: to burn, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttutu îi  \t   1\t   1\n",
      "Tahitian_173     \ttutu îi  \t   1\t   1\n",
      "Hawaiian_52      \tkuni    \t   1\t   3\n",
      "Tuamotuan_246    \ttu≈ãi    \t   1\t   3\n",
      "Sikaiana_243     \ttuÀênia  \t   1\t   3\n",
      "Austral_128      \t îa îa îama\t   2\t   2\n",
      "Mangareva_239    \ttutu    \t   4\t   1\n",
      "NorthMarquesan_38\ttutu    \t   4\t   1\n",
      "Rapanui_264      \ttutu    \t   4\t   1\n",
      "Sikaiana_243     \ttutu    \t   4\t   1\n",
      "Maori_85         \ttahu    \t   5\t   5\n",
      "Tuamotuan_246    \ttahu    \t   5\t   5\n",
      "Mangareva_239    \tta îu    \t   5\t   5\n",
      "Hawaiian_52      \t îaÀê     \t  11\t  11\n",
      "Mangareva_239    \tka îa    \t  11\t  11\n",
      "NorthMarquesan_38\thakau îa \t  13\t  11\n",
      "#\n",
      "Concept: to chew, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îa îa_ma…¢u\t   1\t   1\n",
      "Austral_128      \t îau îau   \t   2\t   2\n",
      "Tahitian_173     \t îau îau   \t   2\t   2\n",
      "Tuamotuan_246    \t≈ãau      \t   2\t  10\n",
      "Hawaiian_52      \tmama     \t   3\t   3\n",
      "Mangareva_239    \t îamama   \t   3\t   3\n",
      "Rapanui_264      \tmama     \t   3\t   3\n",
      "Sikaiana_243     \tmaÀêmaÀê   \t   3\t   3\n",
      "Maori_85         \tkatikati \t   5\t   5\n",
      "NorthMarquesan_38\tnennahhu \t   6\t   6\n",
      "#\n",
      "Concept: to climb, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tpi îi  \t   1\t   1\n",
      "Austral_128      \tpi îi  \t   1\t   1\n",
      "Hawaiian_52      \tpi îi  \t   1\t   1\n",
      "Mangareva_239    \tpiki  \t   1\t   1\n",
      "Maori_85         \tpiki  \t   1\t   1\n",
      "NorthMarquesan_38\thiti  \t   1\t   6\n",
      "Rapanui_264      \teke   \t   7\t   7\n",
      "Sikaiana_243     \tkake  \t   8\t   7\n",
      "Tuamotuan_246    \tkake  \t   8\t   7\n",
      "Tahitian_173     \tta îuma\t   9\t   9\n",
      "#\n",
      "Concept: to come, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \thae…¢e_mai\t   1\t   1\n",
      "Austral_128      \t îano_mai \t   1\t   1\n",
      "Maori_85         \thaere_mai\t   1\t   1\n",
      "NorthMarquesan_38\the îe__mai\t   1\t   1\n",
      "Sikaiana_243     \thale_mai \t   1\t   1\n",
      "Tahitian_173     \thaere_mai\t   1\t   1\n",
      "Austral_128      \t îaere_mai\t   1\t   1\n",
      "Hawaiian_52      \tmai      \t   1\t   3\n",
      "Tuamotuan_246    \tmai      \t   1\t   3\n",
      "Mangareva_239    \ta îu      \t   4\t   4\n",
      "Rapanui_264      \ttu îu     \t   7\t   4\n",
      "NorthMarquesan_38\ttihe     \t  12\t  12\n",
      "#\n",
      "Concept: to cook, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ttunu    \t   1\t   1\n",
      "Mangareva_239    \ttunu    \t   1\t   1\n",
      "NorthMarquesan_38\tnunu    \t   1\t   1\n",
      "Rapanui_264      \ttunu    \t   1\t   1\n",
      "Austral_128      \ttunu    \t   1\t   1\n",
      "Tahitian_173     \ttunu    \t   1\t   1\n",
      "Austral_128      \ttau     \t   2\t   2\n",
      "Maori_85         \ttao     \t   2\t   2\n",
      "Sikaiana_243     \ttao     \t   2\t   2\n",
      "Tuamotuan_246    \ttao     \t   2\t   2\n",
      "NorthMarquesan_38\ttao     \t   2\t   2\n",
      "Tahitian_173     \t îeu     \t   2\t   9\n",
      "Hawaiian_52      \tho îomo îa\t   3\t   3\n",
      "#\n",
      "Concept: to count, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ttai îo  \t   1\t   1\n",
      "Austral_128      \ttai îo  \t   1\t   1\n",
      "Tahitian_173     \ttai îo  \t   1\t   1\n",
      "Hawaiian_52      \thelu   \t   3\t   3\n",
      "Mangareva_239    \ttou îara\t   4\t   4\n",
      "Maori_85         \ttatau  \t   4\t   5\n",
      "NorthMarquesan_38\ttau    \t   4\t   5\n",
      "Rapanui_264      \ttataku \t   4\t   5\n",
      "Sikaiana_243     \tpau    \t   4\t   8\n",
      "#\n",
      "Concept: to cut, hack, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttapu_te_…¢a îau\t   1\t   1\n",
      "Austral_128      \ttaÀêpuÀê       \t   1\t   2\n",
      "Tahitian_173     \ttaÀêpuÀê       \t   1\t   2\n",
      "Hawaiian_52      \t îoki         \t   3\t   3\n",
      "Tuamotuan_246    \tkokoti       \t   3\t  10\n",
      "NorthMarquesan_38\tkokoti       \t   3\t  10\n",
      "Mangareva_239    \ttarai        \t   4\t   2\n",
      "Maori_85         \ttaÀê          \t   4\t   2\n",
      "NorthMarquesan_38\tta îai        \t   4\t   2\n",
      "Rapanui_264      \ttarai        \t   4\t   2\n",
      "Rapanui_264      \thore         \t   7\t   7\n",
      "Sikaiana_243     \tsele         \t   8\t   7\n",
      "Hawaiian_52      \tmoku         \t  11\t  11\n",
      "Rapanui_264      \tmotu         \t  11\t  11\n",
      "Mangareva_239    \t îakakiukiu   \t  12\t  12\n",
      "Rapanui_264      \tavahi        \t  14\t  14\n",
      "Tuamotuan_246    \tihi          \t  15\t  15\n",
      "NorthMarquesan_38\t îihi         \t  15\t  15\n",
      "#\n",
      "Concept: to dream, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmoemoeaÀê    \t   1\t   1\n",
      "Mangareva_239    \tmoemoea     \t   1\t   1\n",
      "Maori_85         \tmoemoeaÀê    \t   1\t   1\n",
      "NorthMarquesan_38\tmoemoea     \t   1\t   1\n",
      "Rapanui_264      \tmoe         \t   1\t   1\n",
      "Tahitian_173     \tmoemoeaÀê    \t   1\t   1\n",
      "Tuamotuan_246    \tmoemoeaÀê    \t   1\t   1\n",
      "Austral_128      \tmoemoeaÀê    \t   1\t   1\n",
      "Hawaiian_52      \tmoemoeaÀê    \t   1\t   1\n",
      "Austral_128      \t îa îa îeimoe  \t   1\t   2\n",
      "Hawaiian_52      \tmoe îuhane   \t   1\t   3\n",
      "Tahitian_173     \tta îoto îotoaÀê\t  12\t  12\n",
      "#\n",
      "Concept: to eat, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îamu\t   1\t   1\n",
      "Tahitian_173     \t îamu\t   1\t   1\n",
      "Austral_128      \t îai \t   1\t   2\n",
      "Hawaiian_52      \t îai \t   1\t   2\n",
      "Mangareva_239    \tkai \t   1\t   2\n",
      "Maori_85         \tkai \t   1\t   2\n",
      "NorthMarquesan_38\t îai \t   1\t   2\n",
      "Rapanui_264      \tkai \t   1\t   2\n",
      "Sikaiana_243     \tkai \t   1\t   2\n",
      "Tuamotuan_246    \tkai \t   1\t   2\n",
      "#\n",
      "Concept: to fall, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttopa        \t   1\t   1\n",
      "Austral_128      \ttopa        \t   1\t   1\n",
      "Mangareva_239    \ttopa        \t   1\t   1\n",
      "Tahitian_173     \ttopa        \t   1\t   1\n",
      "Rapanui_264      \ttopa        \t   1\t   1\n",
      "NorthMarquesan_38\ttopa        \t   1\t   1\n",
      "Tuamotuan_246    \ttopa        \t   1\t   1\n",
      "Hawaiian_52      \thaÀê îule     \t   3\t   3\n",
      "Maori_85         \tmakere      \t   5\t   5\n",
      "Tuamotuan_246    \tmakiri      \t   5\t   5\n",
      "NorthMarquesan_38\tmek îee      \t   5\t  21\n",
      "NorthMarquesan_38\thuÀê_te_henua\t   6\t   6\n",
      "Rapanui_264      \thiga        \t   7\t   7\n",
      "Sikaiana_243     \tsina        \t   7\t   7\n",
      "Tuamotuan_246    \thi≈ãa        \t   7\t   7\n",
      "NorthMarquesan_38\thina        \t   7\t   7\n",
      "Austral_128      \tmarua       \t  11\t  11\n",
      "Mangareva_239    \tmarere      \t  12\t   5\n",
      "Tuamotuan_246    \tmarere      \t  12\t   5\n",
      "NorthMarquesan_38\tvi îi        \t  13\t  13\n",
      "NorthMarquesan_38\tmoku îu      \t  20\t  20\n",
      "#\n",
      "Concept: to flow, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttahe\t   1\t   1\n",
      "Austral_128      \tta îe\t   1\t   1\n",
      "Hawaiian_52      \tkahe\t   1\t   1\n",
      "Mangareva_239    \tta îe\t   1\t   1\n",
      "Maori_85         \ttere\t   1\t   1\n",
      "NorthMarquesan_38\ttahe\t   1\t   1\n",
      "Rapanui_264      \ttehe\t   1\t   1\n",
      "Tahitian_173     \ttahe\t   1\t   1\n",
      "Tuamotuan_246    \ttahe\t   1\t   1\n",
      "Sikaiana_243     \tlele\t   8\t   1\n",
      "#\n",
      "Concept: to hear, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tha îa…¢o îo   \t   1\t   1\n",
      "Hawaiian_52      \tho îolono   \t   1\t   1\n",
      "Mangareva_239    \t îakaro≈ão   \t   1\t   1\n",
      "Maori_85         \tro≈ão       \t   1\t   1\n",
      "NorthMarquesan_38\t îono       \t   1\t   1\n",
      "Sikaiana_243     \tlono       \t   1\t   1\n",
      "Tahitian_173     \tfa îaro îo   \t   1\t   1\n",
      "Tuamotuan_246    \tro≈ão       \t   1\t   1\n",
      "Austral_128      \t îiÀêro îaro îa\t   1\t   2\n",
      "Rapanui_264      \tgaro îa     \t   1\t   2\n",
      "#\n",
      "Concept: to hide, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ttaÀêponiponi\t   1\t   1\n",
      "Mangareva_239    \tpupuni     \t   1\t   1\n",
      "Tahitian_173     \ttaÀêpuni    \t   1\t   1\n",
      "Austral_128      \t îuna       \t   1\t   2\n",
      "Hawaiian_52      \thuÀênaÀê     \t   1\t   2\n",
      "Maori_85         \thuna       \t   1\t   2\n",
      "Tuamotuan_246    \ttaÀêhuna    \t   1\t   2\n",
      "NorthMarquesan_38\thakanaÀê    \t   6\t   6\n",
      "Rapanui_264      \tromi       \t   7\t   7\n",
      "#\n",
      "Concept: to hit, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tpa îi   \t   1\t   1\n",
      "Mangareva_239    \tpaki   \t   1\t   1\n",
      "Tuamotuan_246    \tpapaki \t   1\t   1\n",
      "Austral_128      \ttaÀê îiri\t   2\t   2\n",
      "Tahitian_173     \ttaÀê îiri\t   2\t   2\n",
      "Hawaiian_52      \thahau  \t   3\t   3\n",
      "Mangareva_239    \ttata   \t   4\t   4\n",
      "Sikaiana_243     \ttaÀê    \t   4\t   4\n",
      "NorthMarquesan_38\tta     \t   4\t   4\n",
      "Tuamotuan_246    \ttaÀê    \t   4\t   4\n",
      "Maori_85         \tpatu   \t   5\t   5\n",
      "NorthMarquesan_38\tpatu   \t   5\t   5\n",
      "Mangareva_239    \tpatu   \t   5\t   5\n",
      "Tuamotuan_246    \tpatu   \t   5\t   5\n",
      "Rapanui_264      \ttutu   \t   7\t   4\n",
      "Tuamotuan_246    \ttuki   \t  10\t   2\n",
      "Hawaiian_52      \tku îi   \t  10\t   2\n",
      "NorthMarquesan_38\ttu îi   \t  10\t   2\n",
      "NorthMarquesan_38\tpehi   \t  18\t   1\n",
      "#\n",
      "Concept: to hold, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t…¢ave   \t   1\t   1\n",
      "Austral_128      \ttaÀêpe îa\t   2\t   2\n",
      "Tahitian_173     \ttaÀêpe îa\t   2\t   2\n",
      "Hawaiian_52      \tpa îa   \t   3\t   2\n",
      "Mangareva_239    \ttaÀêmau \t   4\t   4\n",
      "NorthMarquesan_38\tmau    \t   4\t   4\n",
      "Maori_85         \tpupuri \t   5\t   5\n",
      "Rapanui_264      \tkuku   \t   7\t   7\n",
      "Sikaiana_243     \ttaohi  \t   8\t   8\n",
      "Tuamotuan_246    \tta≈ão   \t  10\t  10\n",
      "NorthMarquesan_38\t îi îima \t  11\t  11\n",
      "Rapanui_264      \taÀêru   \t  12\t  12\n",
      "#\n",
      "Concept: to hunt, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ta îua îu\t   1\t   1\n",
      "Austral_128      \ta îua îu\t   1\t   1\n",
      "Tahitian_173     \ta îua îu\t   1\t   1\n",
      "Tuamotuan_246    \takuaku\t   1\t   1\n",
      "Hawaiian_52      \thahai \t   3\t   3\n",
      "Maori_85         \tfaifai\t   3\t   5\n",
      "Mangareva_239    \taruaru\t   4\t   4\n",
      "NorthMarquesan_38\ttatai \t   6\t   6\n",
      "Rapanui_264      \tpoko  \t   7\t   7\n",
      "Sikaiana_243     \tsese  \t   8\t   8\n",
      "#\n",
      "Concept: to lie down, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttiÀê…¢aha   \t   1\t   1\n",
      "Austral_128      \ttiÀêra îa   \t   1\t   1\n",
      "Austral_128      \ttaÀêrava   \t   2\t   1\n",
      "Hawaiian_52      \thina_moe  \t   3\t   3\n",
      "NorthMarquesan_38\tmoe       \t   3\t   6\n",
      "Rapanui_264      \tmoe       \t   3\t   6\n",
      "Sikaiana_243     \tmoe       \t   3\t   6\n",
      "Mangareva_239    \t îakaeara≈ãa\t   4\t   4\n",
      "Maori_85         \ttakoto    \t   5\t   5\n",
      "Tahitian_173     \tta îoto    \t   5\t   5\n",
      "Tuamotuan_246    \ttakoto    \t   5\t   5\n",
      "Austral_128      \ttiÀêpapa   \t  11\t  11\n",
      "#\n",
      "Concept: to open, uncover, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îi…¢iti \t   1\t   1\n",
      "Austral_128      \t îiriti \t   1\t   1\n",
      "Austral_128      \t îua îi  \t   2\t   2\n",
      "Maori_85         \thuaki  \t   2\t   2\n",
      "Tahitian_173     \thua îi  \t   2\t   2\n",
      "Hawaiian_52      \tweke   \t   3\t   3\n",
      "Mangareva_239    \t îu îure \t   4\t   4\n",
      "NorthMarquesan_38\tpe îua  \t   6\t   6\n",
      "Rapanui_264      \thahata \t   7\t   7\n",
      "Sikaiana_243     \taÀêha   \t   7\t  13\n",
      "Sikaiana_243     \ttaÀêlaki\t   8\t   8\n",
      "Tuamotuan_246    \theheu  \t  10\t  10\n",
      "NorthMarquesan_38\tpepeu  \t  10\t  12\n",
      "#\n",
      "Concept: to pound, beat, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \to…¢oÀê…¢o   \t   1\t   1\n",
      "Austral_128      \tpa îi     \t   2\t   2\n",
      "Hawaiian_52      \tku îi     \t   3\t   3\n",
      "Mangareva_239    \ttuki     \t   3\t   3\n",
      "Maori_85         \ttuki     \t   3\t   3\n",
      "NorthMarquesan_38\ttu îi     \t   3\t   3\n",
      "Sikaiana_243     \ttuki     \t   3\t   3\n",
      "Tuamotuan_246    \ttuki     \t   3\t   3\n",
      "Austral_128      \ttu îi     \t   3\t   3\n",
      "Tahitian_173     \tpaÀêpaÀêhia\t   8\t   2\n",
      "#\n",
      "Concept: to see, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îite  \t   1\t   1\n",
      "Hawaiian_52      \t îike  \t   1\t   1\n",
      "Maori_85         \tkite  \t   1\t   1\n",
      "NorthMarquesan_38\t îite  \t   1\t   1\n",
      "Sikaiana_243     \tkite  \t   1\t   1\n",
      "Tahitian_173     \t îite  \t   1\t   1\n",
      "Tuamotuan_246    \tkite  \t   1\t   1\n",
      "Rapanui_264      \ttikea \t   1\t   7\n",
      "Austral_128      \tnaÀênaÀê\t   2\t   2\n",
      "Mangareva_239    \tnana  \t   2\t   2\n",
      "#\n",
      "Concept: to sleep, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tmoe   \t   1\t   1\n",
      "Austral_128      \tmoe   \t   2\t   1\n",
      "Hawaiian_52      \tmoe   \t   2\t   1\n",
      "Mangareva_239    \tmoe   \t   2\t   1\n",
      "Maori_85         \tmoe   \t   2\t   1\n",
      "NorthMarquesan_38\thiamoe\t   2\t   1\n",
      "Rapanui_264      \tmoe   \t   2\t   1\n",
      "Sikaiana_243     \tmoe   \t   2\t   1\n",
      "Tuamotuan_246    \tmoe   \t   2\t   1\n",
      "Tahitian_173     \tta îoto\t   9\t   9\n",
      "#\n",
      "Concept: to sniff, smell, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \thau îa\t   1\t   1\n",
      "Austral_128      \t îau îa\t   1\t   1\n",
      "Tahitian_173     \thau îa\t   1\t   1\n",
      "Hawaiian_52      \thoni \t   3\t   3\n",
      "Mangareva_239    \t îo≈ãi \t   3\t   3\n",
      "Maori_85         \tho≈ãi \t   3\t   3\n",
      "NorthMarquesan_38\thone \t   3\t   3\n",
      "Rapanui_264      \thogi \t   3\t   3\n",
      "Sikaiana_243     \tsaona\t   3\t   3\n",
      "Tahitian_173     \tho îi \t   3\t   3\n",
      "Tuamotuan_246    \tho≈ãi \t   3\t   3\n",
      "Sikaiana_243     \tsunu \t  11\t   3\n",
      "#\n",
      "Concept: to split, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tpaÀêha…¢a  \t   1\t   1\n",
      "Austral_128      \tvaÀêvaÀê îi \t   2\t   2\n",
      "Hawaiian_52      \twaÀêhi    \t   2\t   2\n",
      "Maori_85         \twaÀêwaÀêhi \t   2\t   2\n",
      "Tahitian_173     \tvaÀêhi    \t   2\t   2\n",
      "Tuamotuan_246    \ttapahi   \t   2\t  10\n",
      "Sikaiana_243     \tvae      \t   2\t  13\n",
      "Mangareva_239    \ta îae     \t   4\t   4\n",
      "NorthMarquesan_38\tkoava    \t   6\t   6\n",
      "Rapanui_264      \tihi      \t   7\t   7\n",
      "Sikaiana_243     \thaÀê      \t   8\t   4\n",
      "Rapanui_264      \tgaha     \t   8\t   4\n",
      "Austral_128      \tna îa îa   \t   8\t  15\n",
      "Austral_128      \tpi îi_ai  \t  11\t  11\n",
      "Tuamotuan_246    \tmaÀêtaÀêtaÀê\t  14\t  14\n",
      "#\n",
      "Concept: to squeeze, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t…¢o…¢omi  \t   1\t   1\n",
      "NorthMarquesan_38\t îomi    \t   1\t   1\n",
      "Austral_128      \tne îine îi\t   2\t   2\n",
      "Hawaiian_52      \t îuwiÀê   \t   3\t   3\n",
      "Mangareva_239    \tkukumu  \t   4\t   1\n",
      "Tahitian_173     \t îu îumu  \t   4\t   1\n",
      "Austral_128      \t îu îumu  \t   4\t   1\n",
      "Maori_85         \tkoteÀê   \t   5\t   5\n",
      "Rapanui_264      \tgatu    \t   7\t   7\n",
      "Sikaiana_243     \tkumi    \t   8\t   1\n",
      "Tuamotuan_246    \t≈ãi≈ãiti  \t  10\t  10\n",
      "NorthMarquesan_38\tkoko    \t  12\t   1\n",
      "NorthMarquesan_38\thota    \t  13\t  13\n",
      "#\n",
      "Concept: to stab, pierce, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tpipiha  \t   1\t   1\n",
      "Austral_128      \tpaÀêtia  \t   2\t   2\n",
      "Tahitian_173     \tpaÀêtia  \t   2\t   2\n",
      "Hawaiian_52      \thou     \t   3\t   3\n",
      "Mangareva_239    \t îuki    \t   4\t   4\n",
      "NorthMarquesan_38\thuki    \t   4\t   4\n",
      "Sikaiana_243     \tsuki    \t   4\t   4\n",
      "Rapanui_264      \thuki    \t   4\t   4\n",
      "Tuamotuan_246    \thuki    \t   4\t   4\n",
      "Maori_85         \toka     \t   5\t   4\n",
      "Rapanui_264      \toka     \t   5\t   4\n",
      "Tuamotuan_246    \thoka    \t   5\t   4\n",
      "Sikaiana_243     \tsoÀêkai  \t   5\t   4\n",
      "Tahitian_173     \tperforer\t   9\t   9\n",
      "Mangareva_239    \tko      \t  11\t  11\n",
      "#\n",
      "Concept: to stand, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \ttia     \t   1\t   1\n",
      "Austral_128      \ttuÀê     \t   2\t   1\n",
      "Hawaiian_52      \tku      \t   2\t   1\n",
      "Maori_85         \ttuÀê     \t   2\t   1\n",
      "NorthMarquesan_38\ttuÀê     \t   2\t   1\n",
      "Rapanui_264      \ttu îu    \t   2\t   1\n",
      "Sikaiana_243     \ttuÀê     \t   2\t   1\n",
      "Tuamotuan_246    \ttuÀê     \t   2\t   1\n",
      "Austral_1213     \ttuÀê     \t   2\t   1\n",
      "Mangareva_239    \t îakaÀêtuÀê\t   2\t   4\n",
      "Tahitian_173     \tti îa    \t   9\t   1\n",
      "#\n",
      "Concept: to steal, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îeiaÀê  \t   1\t   1\n",
      "Austral_128      \t îeiaÀê  \t   1\t   1\n",
      "Sikaiana_243     \tkaiaÀê  \t   1\t   1\n",
      "Tahitian_173     \t îeiaÀê  \t   1\t   1\n",
      "Tuamotuan_246    \tkeiaÀê  \t   1\t   1\n",
      "Hawaiian_52      \t îaihue \t   3\t   3\n",
      "NorthMarquesan_38\tkai_hue\t   3\t  11\n",
      "Mangareva_239    \tkamo   \t   4\t   4\n",
      "NorthMarquesan_38\tkamo   \t   4\t   4\n",
      "Maori_85         \ttaÀêhae \t   5\t   5\n",
      "Rapanui_264      \tkori   \t   7\t   7\n",
      "#\n",
      "Concept: to suck, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îote  \t   1\t   1\n",
      "Austral_128      \t îote  \t   1\t   1\n",
      "Maori_85         \t≈ãote  \t   1\t   1\n",
      "Tahitian_173     \t îote  \t   1\t   1\n",
      "Hawaiian_52      \tomo   \t   3\t   3\n",
      "Mangareva_239    \tomo   \t   3\t   3\n",
      "NorthMarquesan_38\tomo   \t   3\t   3\n",
      "Rapanui_264      \tomo   \t   3\t   3\n",
      "Tuamotuan_246    \t≈ão≈ão  \t   3\t  10\n",
      "Sikaiana_243     \tumiumi\t   8\t   3\n",
      "Mangareva_239    \tmiti  \t  11\t  11\n",
      "Sikaiana_243     \tmmiti \t  11\t  11\n",
      "Tuamotuan_246    \tmiti  \t  11\t  11\n",
      "Tuamotuan_246    \tmomi  \t  13\t   3\n",
      "#\n",
      "Concept: to swell, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \toÀêpupu    \t   1\t   1\n",
      "Tuamotuan_246    \tkoropuÀêpuÀê\t   2\t   1\n",
      "Austral_128      \t îoru      \t   2\t   2\n",
      "Tahitian_173     \t îoru      \t   2\t   2\n",
      "Hawaiian_52      \thuÀê       \t   3\t   2\n",
      "NorthMarquesan_38\thuhu îa    \t   3\t  11\n",
      "Mangareva_239    \t îakatekire\t   4\t   4\n",
      "Maori_85         \tpuku      \t   5\t   5\n",
      "NorthMarquesan_38\thete      \t   6\t   6\n",
      "Rapanui_264      \tahu       \t   7\t   2\n",
      "Sikaiana_243     \thula      \t   7\t   2\n",
      "#\n",
      "Concept: to swim, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \t îau   \t   1\t   1\n",
      "Austral_128      \t îau   \t   1\t   1\n",
      "Hawaiian_52      \t îau   \t   1\t   1\n",
      "Mangareva_239    \tkau   \t   1\t   1\n",
      "Maori_85         \tkauhoe\t   1\t   1\n",
      "NorthMarquesan_38\tkau   \t   1\t   1\n",
      "Rapanui_264      \tkau   \t   1\t   1\n",
      "Tahitian_173     \t îau   \t   1\t   1\n",
      "Tuamotuan_246    \tkau   \t   1\t   1\n",
      "Sikaiana_243     \tkoukou\t   1\t   8\n",
      "#\n",
      "Concept: to think, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \the…¢u…¢i      \t   1\t   1\n",
      "Austral_128      \tmana îo      \t   2\t   2\n",
      "Hawaiian_52      \tmana îo      \t   2\t   2\n",
      "Rapanui_264      \tmana îu      \t   2\t   2\n",
      "Tahitian_173     \tmana îo      \t   2\t   2\n",
      "NorthMarquesan_38\tma îakau     \t   2\t   4\n",
      "Mangareva_239    \tmakara      \t   4\t   4\n",
      "Maori_85         \tfakaÀêro     \t   5\t   4\n",
      "Sikaiana_243     \thakateletele\t   8\t   8\n",
      "Tuamotuan_246    \tmahara      \t  10\t   4\n",
      "#\n",
      "Concept: to throw, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttaÀêo…¢a \t   1\t   1\n",
      "Austral_128      \ttaÀêora \t   1\t   1\n",
      "NorthMarquesan_38\ttio îa  \t   1\t   1\n",
      "Tahitian_173     \ttaÀêora \t   1\t   1\n",
      "Hawaiian_52      \tho îolei\t   3\t   3\n",
      "Mangareva_239    \ttiri   \t   4\t   4\n",
      "NorthMarquesan_38\tti îi   \t   4\t   4\n",
      "Tuamotuan_246    \ttiri   \t   4\t   4\n",
      "Maori_85         \tpa≈ãa   \t   5\t   5\n",
      "Rapanui_264      \tvero   \t   7\t   7\n",
      "Sikaiana_243     \tpehi   \t   8\t   8\n",
      "Tuamotuan_246    \ttoro   \t  10\t   1\n",
      "Mangareva_239    \tkero   \t  11\t   7\n",
      "Tuamotuan_246    \tmaka   \t  14\t  14\n",
      "#\n",
      "Concept: to turn, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \ttaÀêvi…¢i\t   1\t   1\n",
      "NorthMarquesan_38\tkavi îi \t   1\t   1\n",
      "Rapanui_264      \ttaviri \t   1\t   1\n",
      "Hawaiian_52      \twili   \t   1\t   1\n",
      "Austral_128      \ttiÀêpu îu\t   2\t   2\n",
      "Tahitian_173     \ttiÀêpu îu\t   2\t   2\n",
      "Hawaiian_52      \thuli   \t   3\t   3\n",
      "Maori_85         \thuri   \t   3\t   3\n",
      "Sikaiana_243     \ttahuli \t   3\t   3\n",
      "Tuamotuan_246    \thuri   \t   3\t   3\n",
      "Mangareva_239    \ttiÀêrori\t   4\t   1\n",
      "Rapanui_264      \tteka   \t  12\t  12\n",
      "#\n",
      "Concept: to walk, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \thae…¢e          \t   1\t   1\n",
      "Hawaiian_52      \thele           \t   1\t   1\n",
      "Mangareva_239    \t îere           \t   1\t   1\n",
      "NorthMarquesan_38\th îee           \t   1\t   1\n",
      "Rapanui_264      \thaere          \t   1\t   1\n",
      "Sikaiana_243     \tsaele          \t   1\t   1\n",
      "Tuamotuan_246    \thaere          \t   1\t   1\n",
      "Tahitian_173     \thaere          \t   1\t   1\n",
      "Austral_128      \t îano_rimo_ îaere\t   1\t   2\n",
      "Maori_85         \thaere+a+waewae \t   1\t   5\n",
      "Tahitian_173     \tori            \t   9\t   9\n",
      "Austral_128      \trimorimo       \t  11\t  11\n",
      "Austral_128      \t îano           \t  13\t  13\n",
      "#\n",
      "Concept: to work, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îohipa\t   1\t   1\n",
      "Austral_128      \t îatapu\t   2\t   2\n",
      "Hawaiian_52      \thana  \t   3\t   3\n",
      "Mangareva_239    \t îa≈ãa  \t   3\t   3\n",
      "NorthMarquesan_38\thana  \t   3\t   3\n",
      "Tuamotuan_246    \tha≈ãa  \t   3\t   3\n",
      "Rapanui_264      \taga   \t   3\t   7\n",
      "Maori_85         \tmahi  \t   5\t   5\n",
      "Sikaiana_243     \thekau \t   8\t   8\n",
      "Tahitian_173     \t îohipa\t   9\t   1\n",
      "#\n",
      "Concept: to yawn, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \thaÀêmama_te_vaha\t   1\t   1\n",
      "Austral_128      \t îaÀêmama        \t   1\t   1\n",
      "Hawaiian_52      \thaÀêmama        \t   1\t   1\n",
      "Mangareva_239    \t îamama         \t   1\t   1\n",
      "Maori_85         \thaÀêmama        \t   1\t   1\n",
      "NorthMarquesan_38\tmama           \t   1\t   1\n",
      "Tahitian_173     \thaÀêmama        \t   1\t   1\n",
      "Tuamotuan_246    \thaÀêmama        \t   1\t   1\n",
      "Rapanui_264      \thaka           \t   1\t   7\n",
      "Mangareva_239    \tnaro           \t  10\t  10\n",
      "#\n",
      "Concept: tongue, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \ta…¢e…¢o\t   1\t   1\n",
      "Austral_128      \tarero\t   1\t   1\n",
      "Hawaiian_52      \talelo\t   1\t   1\n",
      "Mangareva_239    \tarero\t   1\t   1\n",
      "Maori_85         \tarero\t   1\t   1\n",
      "Rapanui_264      \tarero\t   1\t   1\n",
      "Sikaiana_243     \talelo\t   1\t   1\n",
      "Tahitian_173     \tarero\t   1\t   1\n",
      "Tuamotuan_246    \tarero\t   1\t   1\n",
      "NorthMarquesan_38\ta î îeo\t   1\t   6\n",
      "#\n",
      "Concept: Twenty, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tpiti_ îahu…¢u\t   1\t   1\n",
      "Austral_128      \tpiti_ îa îuru\t   1\t   1\n",
      "Tahitian_173     \tpiti_ îahuru\t   1\t   1\n",
      "Hawaiian_52      \tiwakaÀêlua  \t   3\t   3\n",
      "Mangareva_239    \ttakau      \t   4\t   4\n",
      "NorthMarquesan_38\ttekau      \t   4\t   4\n",
      "Tahitian_173     \tta îau      \t   4\t   4\n",
      "Maori_85         \trua_tekau  \t   5\t   4\n",
      "#\n",
      "Concept: we, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \tmaÀêtou\t   1\t   1\n",
      "Austral_128      \tmaÀêtou\t   1\t   1\n",
      "Hawaiian_52      \tmaÀêkou\t   1\t   1\n",
      "Rapanui_264      \tmatou \t   1\t   1\n",
      "Tahitian_173     \tmaÀêtou\t   1\t   1\n",
      "Sikaiana_243     \tmaÀêtou\t   1\t   1\n",
      "Maori_85         \tmaÀêtou\t   1\t   1\n",
      "NorthMarquesan_38\tmatou \t   1\t   1\n",
      "Maori_85         \tmaÀêua \t   1\t   4\n",
      "Austral_1213     \tmaÀêua \t   1\t   4\n",
      "Hawaiian_52      \tmaÀêua \t   1\t   4\n",
      "NorthMarquesan_38\tmaua  \t   1\t   4\n",
      "Austral_128      \tmaÀêua \t   1\t   4\n",
      "Sikaiana_243     \tmaÀêua \t   1\t   4\n",
      "Tahitian_173     \tmaÀêua \t   1\t   4\n",
      "Tuamotuan_246    \ttatou \t   4\t   1\n",
      "Austral_128      \ttaÀêtou\t   4\t   1\n",
      "Maori_85         \ttaÀêtou\t   4\t   1\n",
      "NorthMarquesan_38\ttatou \t   4\t   1\n",
      "Rapanui_264      \ttatou \t   4\t   1\n",
      "Tahitian_173     \ttaÀêtou\t   4\t   1\n",
      "Hawaiian_52      \tkaÀêkou\t   4\t   1\n",
      "Sikaiana_243     \ttaÀêtou\t   4\t   1\n",
      "Austral_1213     \ttaÀêtou\t   4\t   1\n",
      "Mangareva_239    \ttaÀêua \t   4\t   4\n",
      "NorthMarquesan_38\ttaua  \t   4\t   4\n",
      "Sikaiana_243     \ttaÀêua \t   4\t   4\n",
      "Austral_1213     \ttaÀêua \t   4\t   4\n",
      "Austral_128      \ttaÀêua \t   4\t   4\n",
      "Maori_85         \ttaÀêua \t   4\t   4\n",
      "Tahitian_173     \ttaÀêua \t   4\t   4\n",
      "Hawaiian_52      \tkaÀêua \t   4\t   4\n",
      "#\n",
      "Concept: what?, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \taha  \t   1\t   1\n",
      "Austral_128      \ta îa  \t   1\t   1\n",
      "Hawaiian_52      \taha  \t   1\t   1\n",
      "Mangareva_239    \ta îa  \t   1\t   1\n",
      "Maori_85         \taha  \t   1\t   1\n",
      "NorthMarquesan_38\taha  \t   1\t   1\n",
      "Rapanui_264      \taha  \t   1\t   1\n",
      "Tuamotuan_246    \taha  \t   1\t   1\n",
      "Sikaiana_243     \taÀê   \t   1\t   8\n",
      "Tahitian_173     \te_aha\t   1\t   9\n",
      "#\n",
      "Concept: when?, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tahea         \t   1\t   1\n",
      "Austral_128      \tinaÀê îea      \t   1\t   1\n",
      "Hawaiian_52      \tinaÀêhea      \t   1\t   1\n",
      "Maori_85         \taÀêhea        \t   1\t   1\n",
      "NorthMarquesan_38\taÀêhea        \t   1\t   1\n",
      "Tahitian_173     \tinaÀêfea      \t   1\t   1\n",
      "Mangareva_239    \ta_ îea        \t   1\t   4\n",
      "Rapanui_264      \tagah îe       \t   1\t   7\n",
      "Sikaiana_243     \tite_moko_ahea\t   1\t   8\n",
      "#\n",
      "Concept: where?, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \thea      \t   1\t   1\n",
      "Austral_128      \t îia      \t   1\t   1\n",
      "Mangareva_239    \t îea      \t   1\t   1\n",
      "Maori_85         \tfea      \t   1\t   1\n",
      "NorthMarquesan_38\thea      \t   1\t   1\n",
      "Rapanui_264      \th îe      \t   1\t   1\n",
      "Sikaiana_243     \thea      \t   1\t   1\n",
      "Tahitian_173     \thea      \t   1\t   1\n",
      "Tuamotuan_246    \thea      \t   1\t   1\n",
      "Hawaiian_52      \taia_i_hea\t   1\t   3\n",
      "#\n",
      "Concept: white, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îuo îuo  \t   1\t   1\n",
      "Austral_128      \tteatea  \t   2\t   2\n",
      "Mangareva_239    \ttea     \t   2\t   2\n",
      "Rapanui_264      \tteatea  \t   2\t   2\n",
      "Sikaiana_243     \ttea     \t   2\t   2\n",
      "Tuamotuan_246    \ttea     \t   2\t   2\n",
      "Hawaiian_52      \tkea     \t   2\t   2\n",
      "NorthMarquesan_38\ttea     \t   2\t   2\n",
      "Hawaiian_52      \tke îoke îo\t   3\t   3\n",
      "NorthMarquesan_38\tteko    \t   3\t  13\n",
      "Maori_85         \tmaÀê     \t   5\t   5\n",
      "NorthMarquesan_38\ttavai îe \t   6\t   6\n",
      "Tahitian_173     \t îuo îuo  \t   9\t   1\n",
      "#\n",
      "Concept: who?, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tvai   \t   1\t   1\n",
      "Austral_128      \tvai   \t   1\t   1\n",
      "Hawaiian_52      \twai   \t   1\t   1\n",
      "Mangareva_239    \tai    \t   1\t   1\n",
      "Maori_85         \twai   \t   1\t   1\n",
      "NorthMarquesan_38\tai    \t   1\t   1\n",
      "Rapanui_264      \taÀêi   \t   1\t   1\n",
      "Sikaiana_243     \tai    \t   1\t   1\n",
      "Tuamotuan_246    \tai    \t   1\t   1\n",
      "Tahitian_173     \t îo_vai\t   1\t   9\n",
      "#\n",
      "Concept: wife, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \tvahine \t   1\t   1\n",
      "Austral_128      \tva îine \t   1\t   1\n",
      "Hawaiian_52      \twahine \t   1\t   1\n",
      "Mangareva_239    \tve îine \t   1\t   1\n",
      "Maori_85         \twahine \t   1\t   1\n",
      "NorthMarquesan_38\tvehine \t   1\t   1\n",
      "Tahitian_173     \tvahine \t   1\t   1\n",
      "Rapanui_264      \tv îiÀê îe \t   7\t   1\n",
      "Tuamotuan_246    \tmoÀêrire\t   9\t   9\n",
      "Mangareva_239    \tahana  \t  10\t   1\n",
      "#\n",
      "Concept: wind, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmata îi \t   1\t   1\n",
      "Austral_128      \tmata îi \t   1\t   1\n",
      "Hawaiian_52      \tmakani \t   1\t   1\n",
      "Mangareva_239    \tmata≈ãi \t   1\t   1\n",
      "NorthMarquesan_38\tmetani \t   1\t   1\n",
      "Sikaiana_243     \tmatani \t   1\t   1\n",
      "Tahitian_173     \tmata îi \t   1\t   1\n",
      "Rapanui_264      \tmatagi \t   1\t   1\n",
      "Tuamotuan_246    \tma+ta≈ãi\t   1\t  10\n",
      "Maori_85         \thau    \t   5\t   5\n",
      "Rapanui_264      \thahau  \t   5\t   5\n",
      "Mangareva_239    \thau    \t   5\t   5\n",
      "Rapanui_264      \ttokerau\t  12\t  12\n",
      "#\n",
      "Concept: wing, False Positives: no, False Negatives: yes\n",
      "Austral_1213     \tmaiti  \t   1\t   1\n",
      "Austral_128      \tpererau\t   2\t   2\n",
      "Mangareva_239    \tpererau\t   2\t   2\n",
      "Maori_85         \tparirau\t   2\t   2\n",
      "Tahitian_173     \tpererau\t   2\t   2\n",
      "Tuamotuan_246    \tpererau\t   2\t   2\n",
      "Hawaiian_52      \t îeÀêheu \t   3\t   3\n",
      "NorthMarquesan_38\tpekeu  \t   3\t   6\n",
      "Sikaiana_243     \tkapakau\t   3\t   6\n",
      "Mangareva_239    \tpehau  \t   3\t   6\n",
      "Rapanui_264      \tkar îa  \t   7\t   7\n",
      "#\n",
      "Concept: woods/forest, False Positives: no, False Negatives: yes\n",
      "Austral_128      \tururaÀê îau \t   1\t   1\n",
      "Tahitian_173     \tururaÀê îau \t   1\t   1\n",
      "Hawaiian_52      \tulu_laÀê îau\t   1\t   2\n",
      "Mangareva_239    \tulu       \t   1\t   9\n",
      "Mangareva_239    \tvao       \t   3\t   3\n",
      "NorthMarquesan_38\tvao       \t   3\t   3\n",
      "Sikaiana_243     \tvao       \t   3\t   3\n",
      "Tuamotuan_246    \tvao       \t   3\t   3\n",
      "Maori_85         \t≈ãahere    \t   4\t   4\n",
      "Tuamotuan_246    \t≈ãahere    \t   4\t   4\n",
      "#\n",
      "Concept: yellow, False Positives: yes, False Negatives: no\n",
      "Austral_1213     \t…¢e îa…¢e îa\t   1\t   1\n",
      "Austral_128      \tre îare îa\t   1\t   1\n",
      "Hawaiian_52      \tlena    \t   1\t   1\n",
      "Tahitian_173     \tre îare îa\t   1\t   1\n",
      "Tuamotuan_246    \tre≈ãare≈ãa\t   1\t   1\n",
      "Mangareva_239    \tre≈ãare≈ãa\t   4\t   1\n",
      "Maori_85         \tkoÀêfai  \t   5\t   5\n",
      "NorthMarquesan_38\ttokatoka\t   6\t   6\n",
      "Rapanui_264      \tpara    \t   7\t   7\n",
      "Sikaiana_243     \tfelo    \t   8\t   8\n",
      "#\n",
      "Concept: you, False Positives: yes, False Negatives: yes\n",
      "Austral_1213     \t îoutou\t   1\t   1\n",
      "Austral_128      \t îoutou\t   1\t   1\n",
      "Hawaiian_52      \t îoukou\t   1\t   1\n",
      "Maori_85         \tkoutou\t   1\t   1\n",
      "NorthMarquesan_38\tkotou \t   1\t   1\n",
      "Sikaiana_243     \tkoutou\t   1\t   1\n",
      "Tahitian_173     \t îoutou\t   1\t   1\n",
      "Tuamotuan_246    \tkoutou\t   1\t   1\n",
      "Mangareva_239    \tkoÀêrua\t   1\t   4\n",
      "Mangareva_239    \tkorua \t   4\t   4\n",
      "Rapanui_264      \tkorua \t   4\t   4\n",
      "Austral_1213     \t îoÀê…¢ua\t   4\t   4\n",
      "Austral_128      \t îuÀêrua\t   4\t   4\n",
      "Hawaiian_52      \t îolua \t   4\t   4\n",
      "Maori_85         \tkoÀêrua\t   4\t   4\n",
      "Sikaiana_243     \tkoulua\t   4\t   4\n",
      "Tahitian_173     \t îoÀêrua\t   4\t   4\n",
      "Tuamotuan_246    \tkoÀêrua\t   4\t   4\n",
      "Mangareva_239    \tkoÀêtou\t  19\t   1\n",
      "#\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d42e8279cfba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cogid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'infomap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "bc, pair, log = diff(wl, 'cogid', 'infomap', tofile=False, pprint=True)\n",
    "print('\\n'.join(log[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see in the output that it contrasts the \"cogid\" with the \"infomap\" numbers by putting them with words and languages in two columns.\n",
    "\n",
    "I assume that the format is more or less self-explaining. Note only one thing: the cognate-ids are always re-computed for each concept set, so you cannot compare them with the ones you find in the text. This is, however, justified, as it helps to compare, since LingPy's `diff` method re-numbers the cognate identifiers for each concept in order to maximally contrast findings by the algorithm and the ones proposed by the experts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Benefits of Segmentation\n",
    "\n",
    "+++ add report on segmentation vs. unsegmented analysis +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Exporting Data\n",
    "\n",
    "It is clear that for many of those who consult automatic cognate detection, they use the methods in order to be able to do more with the data afterwards. LingPy so far supports quite a few different ways to write your data to file for further use in other software packages. A complete integration of `Nexus` files which transport all information which might be relevant for BEAST, however, does not exist yet (but will be added at some point sooner than later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Nexus-Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Distances and Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate distances which would be interesting for packages like SplitsTree (Huson 1998), or also Phylip ([Felsenstein 2005](:ref:Felsenstein2005). For this, you need to be careful, however, since distances can be computed in different ways, and you can choose from a multitude of different distances, and they are not (yet) all documented. The distance calculation as a default counts, how many cognates there are for all concepts between each language pair, so in some way, this tries to mimick Swadesh's original idea of distances or similarities between languages (```$ python3 autocog.py distances``` in commandline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NEXUS\n",
      "\n",
      "BEGIN DATA;\n",
      "DIMENSIONS ntax=10 NCHAR=819;\n",
      "FORMAT DATATYPE=STANDARD GAP=- MISSING=? interleave=yes;\n",
      "MATRIX\n",
      "\n",
      "Austral_1213      100001000000010010000011001000000000001??????11001000000100001100??0??000000111000010110010010??????0??100000??11??10000100110011101000001000101010??????1000000001???001100001001000101110000010001010010001000000010010010000100?????0010010000001100100000001101000000??1?10011100001000010001100010001000000100001000100110010001001000110110000010??0???0100000010??01000?0???????0000001110100011000???110000?????1001000001000100000????00010000001000010001000101000100000100000001000010000010101001011000000000010110001000100100000100001010000010000000???????10000000011000000001010000000001000101100000100000100010010100010100011000000100000000100010000000101001000000101100100001000001100000000001000010000011000001010000100100101011101100000100100001001000001000000011101000000011010?????100110010000110001000011000000001\n",
      "Austral_128       1001100100100100100000110010011000100000100000100100000100000010001100001000010010010110010010000010010100000101100100001001100111010000010010010100010011010000000100001100010001001101110000010101001010001100000010010010100100100001000010000001110100000000110001000100010111101010000010001100110010000010000100000111010010001010000110110000010100000000000101010110001010001000100000110010011000010110000011001101000001000000001100001000000010000010001000111000100000100100000000010010001101011101000000100111111001000011001010000\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from lingpy.convert.strings import pap2nex\n",
    "\n",
    "wl = Wordlist('east-polynesian-lexstat.tsv')\n",
    "paps = wl.get_paps(ref='infomap', missing='?')\n",
    "nexus = pap2nex(wl.cols, paps, missing='?')\n",
    "with io.open('east-polynesian.paps.nex', 'w', encoding='utf8') as fp:\n",
    "    fp.write(nexus)\n",
    "print(nexus[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10\n",
      "Austral_121 0.00 0.27 0.48 0.44 0.49 0.49 0.51 0.63 0.25 0.45\n",
      "Austral_128 0.27 0.00 0.40 0.40 0.42 0.45 0.46 0.57 0.15 0.35\n",
      "Hawaiian_52 0.48 0.40 0.00 0.35 0.40 0.36 0.41 0.51 0.46 0.31\n",
      "Mangareva_2 0.44 0.40 0.35 0.00 0.35 0.29 0.34 0.42 0.45 0.28\n",
      "Maori_85   0.49 0.42 0.40 0.35 0.00 0.38 0.41 0.46 0.47 0.33\n",
      "NorthMarque 0.49 0.45 0.36 0.29 0.38 0.00 0.39 0.43 0.49 0.33\n",
      "Rapanui_264 0.51 0.46 0.41 0.34 0.41 0.39 0.00 0.43 0.48 0.35\n",
      "Sikaiana_24 0.63 0.57 0.51 0.42 0.46 0.43 0.43 0.00 0.59 0.37\n",
      "Tahitian_17 0.25 0.15 0.46 0.45 0.47 0.49 0.48 0.59 0.00 0.40\n",
      "Tuamotuan_2 0.45 0.35 0.31 0.28 0.33 0.33 0.35 0.37 0.40 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lingpy.convert.strings import matrix2dst\n",
    "\n",
    "dst = matrix2dst(wl.get_distances(ref='infomap', mode='swadesh'), wl.taxa)\n",
    "with io.open('east-polynesian.dst', 'w', encoding='utf8') as fp:\n",
    "    fp.write(dst)\n",
    "print(dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format follows strictly the Phylip distance format which also cuts off all language names longer than 10 characters (but there are ways to modify this, I can't show them now).\n",
    "\n",
    "\n",
    "As a final experiment, let us create a tree from the distances, using the simple Neighbor-Joining algorithm, and then print this tree to screen (ignore the warning, ```$ python3 autocogs.py tree```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ‚îå‚îÄSikaiana\n",
      "             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "             ‚îÇ            ‚îÇ            ‚îå‚îÄRapanui\n",
      "             ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "             ‚îÇ                         ‚îÇ            ‚îå‚îÄMaori\n",
      "             ‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "             ‚îÇ                                      ‚îÇ            ‚îå‚îÄHawaiian\n",
      "             ‚îÇ                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                                                   ‚îÇ            ‚îå‚îÄNorthMarqu\n",
      "             ‚îÇ                                                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "             ‚îÇ                                                                ‚îÇ            ‚îå‚îÄMangareva\n",
      "             ‚îÇ                                                                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "             ‚îÇ                                                                             ‚îî‚îÄTuamotuan\n",
      "             ‚îÇ            ‚îå‚îÄAustral\n",
      "             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "                          ‚îÇ            ‚îå‚îÄAustral\n",
      "                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "                                       ‚îî‚îÄTahitian\n"
     ]
    }
   ],
   "source": [
    "from newick import loads\n",
    "tree = loads(wl.get_tree(ref='infomap', tree_calc='upgma'))[0]\n",
    "\n",
    "for node in tree.walk():\n",
    "    if node.name:\n",
    "        node.name = node.name[1:-1].split('_')[0][:10]\n",
    "print(tree.ascii_art(show_internal=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not up to me to judge how good this tree is, and it may also be wrongly rooted in the display. But you can see that LingPy can also handle classical tree formats. Although we do not plan to make LingPy a concurrence for tree inference packages, we find it useful to offer Neighbor-joining and UPGMA just to make it easier for users to quickly evaluate their analyses.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLDF Export\n",
    "\n",
    "+++ maybe @xrotwang should start here +++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "+++ recreate references afterwards again +++"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
